{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HePRcaxsQva"
      },
      "source": [
        "### Workflow 💡💡\n",
        "\n",
        "\n",
        "## CUDA\n",
        "\n",
        "### Basics\n",
        "\n",
        "- Threads, Blocks, Grids   ✅\n",
        "- Memory Hierarchy (global, shared, and local memory)✅\n",
        "\n",
        "- Implement parallel versions of classic algorithms:  \n",
        "  - Matrix multiplication   ✅\n",
        "  - Reduction\n",
        "  - Sorting  \n",
        "\n",
        "### Advanced\n",
        "  - cuBLAS\n",
        "  - cuDNN\n",
        "  - Thrust\n",
        "  -Multi-GPU programming and CUDA\n",
        " streams for concurrent execution\n",
        "\n",
        "\n",
        "### Project Ideas\n",
        "- Optimize an existing ML model’s inference or training pipeline using CUDA. ⚙️  \n",
        "Custom Layers  \n",
        "- Implement custom CUDA kernels for specific operations in an ML pipeline:  \n",
        "  - Novel activation function  \n",
        "  - Custom loss function  \n",
        "\n",
        "  \n",
        "  - Model parallelism\n",
        "  - Distributed training\n",
        "  - Quantization\n",
        "  - Optimize training/inference using CUDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMS5rAKwmrjw",
        "outputId": "e99560fa-c5f4-45d3-ac53-380ae8e7ee31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.11\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpw7rzml6a\".\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BToVMll3JHWu",
        "outputId": "a8cfaaff-d4e6-49d2-fbc9-029037656e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package cuda-toolkit-11-2\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2025.1.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp311-cp311-linux_x86_64.whl size=660362 sha256=0654fbc7f8d4469af246bacfee13763eee4f8b3117c6574ce883c11f44cc06a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/66/50/c65e6116d7e0e16abe0f7c19b50327f76724ccfefbdc61a1b9\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.9 pycuda-2024.1.2 pytools-2025.1.1\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y cuda-toolkit-11-2  # Install CUDA toolkit (adjust version if needed)\n",
        "!nvcc --version  # Verify CUDA compiler installation\n",
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-N_ObZOszw5"
      },
      "source": [
        "#CUDA program surface level runtime:\n",
        "\n",
        "### copy input from host to device\n",
        "### load GPU program and execute using the transferred on-device data\n",
        "### copy results from device back to host so you can display/use it some"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQyaZMJDnv5y"
      },
      "source": [
        "### Cuda Naming\n",
        "\n",
        "#### `h_A` - refers to host (CPU) for variable name “A”\n",
        "#### `d_A` - refers to device (GPU) for variable name “A”\n",
        "#### `__global__`- visible globally, meaning the CPU or host can call these global functions.\n",
        "#### `__device__`\n",
        "#### `__host__`\n",
        "\n",
        "\n",
        "### Memory Allocation in GPU VRAM\n",
        "\n",
        "### `cudaMalloc` - Global memory on GPU itself\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJmgA-8zyD1_"
      },
      "source": [
        "\n",
        "`    float *d_a, *d_b, *d_c; // float array which is a pointer on the device for a , b and c`\n",
        "\n",
        "    cudaMalloc(&d_a, N*N*sizeof(float));\n",
        "    cudaMalloc(&d_b, N*N*sizeof(float));\n",
        "    cudaMalloc(&d_c, N*N*sizeof(float));`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x5kp57umvQG",
        "outputId": "23ca9a1f-68c1-49d3-92c5-587aec0dbb05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_add.cu\n",
        "// vector_add.cu\n",
        "__global__ void vector_add(float *a, float *b, float *c, int n) {\n",
        "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  if (idx < n) {\n",
        "    c[idx] = a[idx] + b[idx];\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRcOi_sIB4mn"
      },
      "source": [
        "Using `nvcc` to compile the `.cu` file into a shared object `(.so)` file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUvtGJPYmvNF"
      },
      "outputs": [],
      "source": [
        "!nvcc -o vector_add.cu --shared -Xcompiler -fPIC vector_add.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUfMOiGJMxUT"
      },
      "outputs": [],
      "source": [
        "!nvcc -ptx vector_add.cu -o vector_add.ptx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq0cLCPdGcId"
      },
      "source": [
        "#### Loading compiled kernel using PyCUDA in python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoBg9fMjIOuG",
        "outputId": "662c3586-4b11-47a1-af8f-a83f5126078b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2025.1.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp311-cp311-linux_x86_64.whl size=660362 sha256=6b9d10fa015d96885d9c5174298cd3c664ad41e239cb6dacd76e56e2aceb6aad\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/66/50/c65e6116d7e0e16abe0f7c19b50327f76724ccfefbdc61a1b9\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.9 pycuda-2024.1.2 pytools-2025.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EYkbNwChM5BN",
        "outputId": "a3964b89-27fa-4e61-9d9b-0058af9a9012"
      },
      "outputs": [
        {
          "ename": "CompileError",
          "evalue": "nvcc compilation of /tmp/tmpnh198ou8/kernel.cu failed\n[command: nvcc --cubin -arch sm_80 -I/usr/local/lib/python3.11/dist-packages/pycuda/cuda kernel.cu]\n[stderr:\nkernel.cu(10): error: expected a declaration\n  .version 8.5\n  ^\n\nkernel.cu(38): error: unrecognized token\n   @%p1 bra $L__BB0_2;\n   ^\n\nkernel.cu(43): warning #12-D: parsing restarts here after previous syntax error\n   cvta.to.global.u64 %rd7, %rd2;\n                                ^\n\nRemark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n\nkernel.cu(44): error: this declaration has no storage class or type specifier\n   add.s64 %rd8, %rd7, %rd5;\n   ^\n\nkernel.cu(44): error: expected a \";\"\n   add.s64 %rd8, %rd7, %rd5;\n      ^\n\nkernel.cu(45): error: this declaration has no storage class or type specifier\n   ld.global.f32 %f1, [%rd8];\n   ^\n\nkernel.cu(45): error: expected a \";\"\n   ld.global.f32 %f1, [%rd8];\n     ^\n\nkernel.cu(46): error: this declaration has no storage class or type specifier\n   ld.global.f32 %f2, [%rd6];\n   ^\n\nkernel.cu(46): error: variable \"ld\" has already been defined\n   ld.global.f32 %f2, [%rd6];\n   ^\n\nkernel.cu(46): error: expected a \";\"\n   ld.global.f32 %f2, [%rd6];\n     ^\n\nkernel.cu(47): error: this declaration has no storage class or type specifier\n   add.f32 %f3, %f2, %f1;\n   ^\n\nkernel.cu(47): error: variable \"add\" has already been defined\n   add.f32 %f3, %f2, %f1;\n   ^\n\nkernel.cu(47): error: expected a \";\"\n   add.f32 %f3, %f2, %f1;\n      ^\n\nkernel.cu(48): error: this declaration has no storage class or type specifier\n   cvta.to.global.u64 %rd9, %rd3;\n   ^\n\nkernel.cu(48): error: expected a \";\"\n   cvta.to.global.u64 %rd9, %rd3;\n       ^\n\nkernel.cu(49): error: this declaration has no storage class or type specifier\n   add.s64 %rd10, %rd9, %rd5;\n   ^\n\nkernel.cu(49): error: variable \"add\" has already been defined\n   add.s64 %rd10, %rd9, %rd5;\n   ^\n\nkernel.cu(49): error: expected a \";\"\n   add.s64 %rd10, %rd9, %rd5;\n      ^\n\nkernel.cu(50): error: this declaration has no storage class or type specifier\n   st.global.f32 [%rd10], %f3;\n   ^\n\nkernel.cu(50): error: expected a \";\"\n   st.global.f32 [%rd10], %f3;\n     ^\n\nkernel.cu(52): error: this declaration has no storage class or type specifier\n  $L__BB0_2:\n  ^\n\nkernel.cu(52): error: expected a \";\"\n  $L__BB0_2:\n           ^\n\nkernel.cu(58): error: expected a declaration\n  }\n  ^\n\n22 errors detected in the compilation of \"kernel.cu\".\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCompileError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-bc0549d3bae3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create a SourceModule from the PTX code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptx_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Get the kernel function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         cubin = compile(\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mnvcc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs, target)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-I\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompile_plain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mcompile_plain\u001b[0;34m(source, options, keep, nvcc, cache_dir, target)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompileError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise CompileError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"nvcc compilation of %s failed\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcu_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mcmdline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCompileError\u001b[0m: nvcc compilation of /tmp/tmpnh198ou8/kernel.cu failed\n[command: nvcc --cubin -arch sm_80 -I/usr/local/lib/python3.11/dist-packages/pycuda/cuda kernel.cu]\n[stderr:\nkernel.cu(10): error: expected a declaration\n  .version 8.5\n  ^\n\nkernel.cu(38): error: unrecognized token\n   @%p1 bra $L__BB0_2;\n   ^\n\nkernel.cu(43): warning #12-D: parsing restarts here after previous syntax error\n   cvta.to.global.u64 %rd7, %rd2;\n                                ^\n\nRemark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n\nkernel.cu(44): error: this declaration has no storage class or type specifier\n   add.s64 %rd8, %rd7, %rd5;\n   ^\n\nkernel.cu(44): error: expected a \";\"\n   add.s64 %rd8, %rd7, %rd5;\n      ^\n\nkernel.cu(45): error: this declaration has no storage class or type specifier\n   ld.global.f32 %f1, [%rd8];\n   ^\n\nkernel.cu(45): error: expected a \";\"\n   ld.global.f32 %f1, [%rd8];\n     ^\n\nkernel.cu(46): error: this declaration has no storage class or type specifier\n   ld.global.f32 %f2, [%rd6];\n   ^\n\nkernel.cu(46): error: variable \"ld\" has already been defined\n   ld.global.f32 %f2, [%rd6];\n   ^\n\nkernel.cu(46): error: expected a \";\"\n   ld.global.f32 %f2, [%rd6];\n     ^\n\nkernel.cu(47): error: this declaration has no storage class or type specifier\n   add.f32 %f3, %f2, %f1;\n   ^\n\nkernel.cu(47): error: variable \"add\" has already been defined\n   add.f32 %f3, %f2, %f1;\n   ^\n\nkernel.cu(47): error: expected a \";\"\n   add.f32 %f3, %f2, %f1;\n      ^\n\nkernel.cu(48): error: this declaration has no storage class or type specifier\n   cvta.to.global.u64 %rd9, %rd3;\n   ^\n\nkernel.cu(48): error: expected a \";\"\n   cvta.to.global.u64 %rd9, %rd3;\n       ^\n\nkernel.cu(49): error: this declaration has no storage class or type specifier\n   add.s64 %rd10, %rd9, %rd5;\n   ^\n\nkernel.cu(49): error: variable \"add\" has already been defined\n   add.s64 %rd10, %rd9, %rd5;\n   ^\n\nkernel.cu(49): error: expected a \";\"\n   add.s64 %rd10, %rd9, %rd5;\n      ^\n\nkernel.cu(50): error: this declaration has no storage class or type specifier\n   st.global.f32 [%rd10], %f3;\n   ^\n\nkernel.cu(50): error: expected a \";\"\n   st.global.f32 [%rd10], %f3;\n     ^\n\nkernel.cu(52): error: this declaration has no storage class or type specifier\n  $L__BB0_2:\n  ^\n\nkernel.cu(52): error: expected a \";\"\n  $L__BB0_2:\n           ^\n\nkernel.cu(58): error: expected a declaration\n  }\n  ^\n\n22 errors detected in the compilation of \"kernel.cu\".\n]"
          ]
        }
      ],
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# Load the precompiled PTX file\n",
        "with open(\"vector_add.ptx\", \"r\") as f:\n",
        "    ptx_code = f.read()\n",
        "\n",
        "# Create a SourceModule from the PTX code\n",
        "mod = SourceModule(ptx_code)\n",
        "\n",
        "# Get the kernel function\n",
        "vector_add = mod.get_function(\"vector_add\")\n",
        "\n",
        "# Define input vectors\n",
        "n = 10**6  # Increase vector size for better GPU utilization\n",
        "a = np.random.randn(n).astype(np.float32)\n",
        "b = np.random.randn(n).astype(np.float32)\n",
        "c = np.zeros_like(a)\n",
        "\n",
        "# Allocate memory on the GPU\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "# Copy data to the GPU\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "# Adjust block and grid sizes\n",
        "block_size = min(256, n)  # Use the smaller of 256 or n\n",
        "grid_size = (n + block_size - 1) // block_size\n",
        "\n",
        "# Launch the kernel\n",
        "vector_add(a_gpu, b_gpu, c_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
        "\n",
        "# Copy the result back to the host\n",
        "cuda.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "# Verify the result\n",
        "print(\"A:\", a[:10])  # Print only the first 10 elements for brevity\n",
        "print(\"B:\", b[:10])\n",
        "print(\"C (A + B):\", c[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "Y2kMiSkvmvKa",
        "outputId": "741a46cf-c5b6-49a9-a624-e0b0a9d01898"
      },
      "outputs": [
        {
          "ename": "CompileError",
          "evalue": "nvcc compilation of /tmp/tmpnoqlc3xf/kernel.cu failed\n[command: nvcc --cubin -arch sm_80 -I/usr/local/lib/python3.11/dist-packages/pycuda/cuda kernel.cu]\n[stderr:\nkernel.cu(2): warning #1654-D: too many characters in character literal -- extra leading characters ignored\n  b'// vector_add.cu\\n__global__ void vector_add(float *a, float *b, float *c, int n) {\\n  int idx = threadIdx.x + blockIdx.x * blockDim.x;\\n  if (idx < n) {\\n    c[idx] = a[idx] + b[idx]\\n  }\\n}\\n'\n   ^\n\nRemark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n\nkernel.cu(2): error: this declaration has no storage class or type specifier\n  b'// vector_add.cu\\n__global__ void vector_add(float *a, float *b, float *c, int n) {\\n  int idx = threadIdx.x + blockIdx.x * blockDim.x;\\n  if (idx < n) {\\n    c[idx] = a[idx] + b[idx]\\n  }\\n}\\n'\n  ^\n\nkernel.cu(2): error: expected a \";\"\n  b'// vector_add.cu\\n__global__ void vector_add(float *a, float *b, float *c, int n) {\\n  int idx = threadIdx.x + blockIdx.x * blockDim.x;\\n  if (idx < n) {\\n    c[idx] = a[idx] + b[idx]\\n  }\\n}\\n'\n   ^\n\n2 errors detected in the compilation of \"kernel.cu\".\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCompileError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-33f47ff13d60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the CUDA kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vector_add.cu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Get the kernel function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         cubin = compile(\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mnvcc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs, target)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-I\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompile_plain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mcompile_plain\u001b[0;34m(source, options, keep, nvcc, cache_dir, target)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompileError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise CompileError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"nvcc compilation of %s failed\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcu_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mcmdline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCompileError\u001b[0m: nvcc compilation of /tmp/tmpnoqlc3xf/kernel.cu failed\n[command: nvcc --cubin -arch sm_80 -I/usr/local/lib/python3.11/dist-packages/pycuda/cuda kernel.cu]\n[stderr:\nkernel.cu(2): warning #1654-D: too many characters in character literal -- extra leading characters ignored\n  b'// vector_add.cu\\n__global__ void vector_add(float *a, float *b, float *c, int n) {\\n  int idx = threadIdx.x + blockIdx.x * blockDim.x;\\n  if (idx < n) {\\n    c[idx] = a[idx] + b[idx]\\n  }\\n}\\n'\n   ^\n\nRemark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n\nkernel.cu(2): error: this declaration has no storage class or type specifier\n  b'// vector_add.cu\\n__global__ void vector_add(float *a, float *b, float *c, int n) {\\n  int idx = threadIdx.x + blockIdx.x * blockDim.x;\\n  if (idx < n) {\\n    c[idx] = a[idx] + b[idx]\\n  }\\n}\\n'\n  ^\n\nkernel.cu(2): error: expected a \";\"\n  b'// vector_add.cu\\n__global__ void vector_add(float *a, float *b, float *c, int n) {\\n  int idx = threadIdx.x + blockIdx.x * blockDim.x;\\n  if (idx < n) {\\n    c[idx] = a[idx] + b[idx]\\n  }\\n}\\n'\n   ^\n\n2 errors detected in the compilation of \"kernel.cu\".\n]"
          ]
        }
      ],
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load the CUDA kernel\n",
        "with open(\"vector_add.cu\", \"rb\") as f:\n",
        "    mod = SourceModule(f.read())\n",
        "\n",
        "# Get the kernel function\n",
        "vector_add = mod.get_function(\"vector_add\")\n",
        "\n",
        "# Define input vectors\n",
        "n = 10**6  # Increase vector size for better GPU utilization\n",
        "a = np.random.randn(n).astype(np.float32)\n",
        "b = np.random.randn(n).astype(np.float32)\n",
        "c = np.zeros_like(a)\n",
        "\n",
        "# Allocate memory on the GPU\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "# Copy data to the GPU\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "# Adjust block and grid sizes\n",
        "block_size = min(256, n)  # Use the smaller of 256 or n\n",
        "grid_size = (n + block_size - 1) // block_size\n",
        "\n",
        "# Launch the kernel\n",
        "start = time.time()\n",
        "vector_add(a_gpu, b_gpu, c_gpu, np.int32(n), block=(block_size, 1, 1), grid=(grid_size, 1))\n",
        "end = time.time()\n",
        "print(f\"Kernel execution time: {end - start:.4f} seconds\")\n",
        "\n",
        "# Copy the result back to the host\n",
        "cuda.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "# Verify the result\n",
        "print(\"A:\", a[:10])  # Print only the first 10 elements for brevity\n",
        "print(\"B:\", b[:10])\n",
        "print(\"C (A + B):\", c[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo-lidlTj16h",
        "outputId": "47513090-dcba-4d20-8c27-dae9c876fd64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package cuda-toolkit-11-2\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y cuda-toolkit-11-2  # Install CUDA toolkit\n",
        "!nvcc --version  # Verify installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHVFUnUZcb8O",
        "outputId": "55db2d43-2927-400c-990f-9d5861326f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting idxing.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile idxing.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// vector_add.cu\n",
        "\n",
        "__global__ void whoami(void) {\n",
        "    int block_id =\n",
        "        blockIdx.x +    // apartment number on this floor (points across)\n",
        "        blockIdx.y * gridDim.x +    // floor number in this building (rows high)\n",
        "        blockIdx.z * gridDim.x * gridDim.y;   //dims of x and y on the grid\n",
        "\n",
        "    int block_offset =\n",
        "        block_id * // times our apartment number\n",
        "        blockDim.x * blockDim.y * blockDim.z; // total threads per block (people per apartment)\n",
        "                                              // how big that block is\n",
        "    int thread_offset =\n",
        "        threadIdx.x +                         // which thread is it within that block\n",
        "        threadIdx.y * blockDim.x +\n",
        "        threadIdx.z * blockDim.x * blockDim.y;\n",
        "\n",
        "    int id = block_offset + thread_offset; // global person id in the entire apartment complex\n",
        "\n",
        "    printf(\"%04d | Block(%d %d %d) = %3d | Thread(%d %d %d) = %3d\\n\",\n",
        "        id,\n",
        "        blockIdx.x, blockIdx.y, blockIdx.z, block_id,\n",
        "        threadIdx.x, threadIdx.y, threadIdx.z, thread_offset);\n",
        "    // printf(\"blockIdx.x: %d, blockIdx.y: %d, blockIdx.z: %d, threadIdx.x: %d, threadIdx.y: %d, threadIdx.z: %d\\n\", blockIdx.x, blockIdx.y, blockIdx.z, threadIdx.x, threadIdx.y, threadIdx.z);\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    const int b_x = 2, b_y = 3, b_z = 4; // shape of the block, think shape of matrix in for eg np\n",
        "    const int t_x = 4, t_y = 4, t_z = 4; // the max warp size is 32, so (shape of grid)\n",
        "    // we will get 2 warp of 32 threads per block\n",
        "\n",
        "    int blocks_per_grid = b_x * b_y * b_z;\n",
        "    int threads_per_block = t_x * t_y * t_z;\n",
        "\n",
        "    printf(\"%d blocks/grid\\n\", blocks_per_grid);\n",
        "    printf(\"%d threads/block\\n\", threads_per_block);\n",
        "    printf(\"%d total threads\\n\", blocks_per_grid * threads_per_block);\n",
        "\n",
        "    dim3 blocksPerGrid(b_x, b_y, b_z); // 3d cube of shape 2*3*4 = 24\n",
        "    dim3 threadsPerBlock(t_x, t_y, t_z); // 3d cube of shape 4*4*4 = 64\n",
        "\n",
        "    whoami<<<blocksPerGrid, threadsPerBlock>>>(); // passing our parameters , calling our function basically\n",
        "    cudaDeviceSynchronize();\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cSfbrArj9UR"
      },
      "outputs": [],
      "source": [
        "!nvcc idxing.cu -o idxing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4juAtwzHkCq6",
        "outputId": "880e94e5-d3c4-474c-d7bd-355d3bb71353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24 blocks/grid\n",
            "64 threads/block\n",
            "1536 total threads\n"
          ]
        }
      ],
      "source": [
        "!./idxing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cec1z25noxo_",
        "outputId": "a7e43d09-013b-4a82-8a7e-92801ed599f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t.headerflags\t@\"EF_CUDA_TEXMODE_UNIFIED EF_CUDA_64BIT_ADDRESS EF_CUDA_SM52 EF_CUDA_VIRTUAL_SM(EF_CUDA_SM52)\"\n",
            "\t.elftype\t@\"ET_EXEC\"\n",
            "\n",
            "\n",
            "//--------------------- .nv.info                  --------------------------\n",
            "\t.section\t.nv.info,\"\",@\"SHT_CUDA_INFO\"\n",
            "\t.align\t4\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_REGCOUNT\n",
            "\t.align\t\t4\n",
            "        /*0000*/ \t.byte\t0x04, 0x2f\n",
            "        /*0002*/ \t.short\t(.L_2 - .L_1)\n",
            "\t.align\t\t4\n",
            ".L_1:\n",
            "        /*0004*/ \t.word\tindex@(_Z6whoamiv)\n",
            "        /*0008*/ \t.word\t0x00000014\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_MIN_STACK_SIZE\n",
            "\t.align\t\t4\n",
            ".L_2:\n",
            "        /*000c*/ \t.byte\t0x04, 0x12\n",
            "        /*000e*/ \t.short\t(.L_4 - .L_3)\n",
            "\t.align\t\t4\n",
            ".L_3:\n",
            "        /*0010*/ \t.word\tindex@(_Z6whoamiv)\n",
            "        /*0014*/ \t.word\t0x00000028\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_FRAME_SIZE\n",
            "\t.align\t\t4\n",
            ".L_4:\n",
            "        /*0018*/ \t.byte\t0x04, 0x11\n",
            "        /*001a*/ \t.short\t(.L_6 - .L_5)\n",
            "\t.align\t\t4\n",
            ".L_5:\n",
            "        /*001c*/ \t.word\tindex@(_Z6whoamiv)\n",
            "        /*0020*/ \t.word\t0x00000028\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_MIN_STACK_SIZE\n",
            "\t.align\t\t4\n",
            ".L_6:\n",
            "        /*0024*/ \t.byte\t0x04, 0x12\n",
            "        /*0026*/ \t.short\t(.L_8 - .L_7)\n",
            "\t.align\t\t4\n",
            ".L_7:\n",
            "        /*0028*/ \t.word\tindex@(_Z6whoamiv)\n",
            "        /*002c*/ \t.word\t0x00000028\n",
            ".L_8:\n",
            "\n",
            "\n",
            "//--------------------- .nv.info._Z6whoamiv       --------------------------\n",
            "\t.section\t.nv.info._Z6whoamiv,\"\",@\"SHT_CUDA_INFO\"\n",
            "\t.sectionflags\t@\"\"\n",
            "\t.align\t4\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_CUDA_API_VERSION\n",
            "\t.align\t\t4\n",
            "        /*0000*/ \t.byte\t0x04, 0x37\n",
            "        /*0002*/ \t.short\t(.L_10 - .L_9)\n",
            ".L_9:\n",
            "        /*0004*/ \t.word\t0x0000007d\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_SW2393858_WAR\n",
            "\t.align\t\t4\n",
            ".L_10:\n",
            "        /*0008*/ \t.byte\t0x01, 0x30\n",
            "\t.zero\t\t2\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_SW1850030_WAR\n",
            "\t.align\t\t4\n",
            "        /*000c*/ \t.byte\t0x01, 0x2a\n",
            "\t.zero\t\t2\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_MAXREG_COUNT\n",
            "\t.align\t\t4\n",
            "        /*0010*/ \t.byte\t0x03, 0x1b\n",
            "        /*0012*/ \t.short\t0x00ff\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_EXTERNS\n",
            "\t.align\t\t4\n",
            "        /*0014*/ \t.byte\t0x04, 0x0f\n",
            "        /*0016*/ \t.short\t(.L_12 - .L_11)\n",
            "\n",
            "\n",
            "\t//   ....[0]....\n",
            "\t.align\t\t4\n",
            ".L_11:\n",
            "        /*0018*/ \t.word\tindex@(vprintf)\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_SYSCALL_OFFSETS\n",
            "\t.align\t\t4\n",
            ".L_12:\n",
            "        /*001c*/ \t.byte\t0x04, 0x46\n",
            "        /*001e*/ \t.short\t(.L_14 - .L_13)\n",
            "\n",
            "\n",
            "\t//   ....[0]....\n",
            ".L_13:\n",
            "        /*0020*/ \t.word\t0x000001c8\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_S2RCTAID_INSTR_OFFSETS\n",
            "\t.align\t\t4\n",
            ".L_14:\n",
            "        /*0024*/ \t.byte\t0x04, 0x1d\n",
            "        /*0026*/ \t.short\t(.L_16 - .L_15)\n",
            "\n",
            "\n",
            "\t//   ....[0]....\n",
            ".L_15:\n",
            "        /*0028*/ \t.word\t0x00000018\n",
            "\n",
            "\n",
            "\t//   ....[1]....\n",
            "        /*002c*/ \t.word\t0x00000030\n",
            "\n",
            "\n",
            "\t//   ....[2]....\n",
            "        /*0030*/ \t.word\t0x00000070\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_EXIT_INSTR_OFFSETS\n",
            "\t.align\t\t4\n",
            ".L_16:\n",
            "        /*0034*/ \t.byte\t0x04, 0x1c\n",
            "        /*0036*/ \t.short\t(.L_18 - .L_17)\n",
            "\n",
            "\n",
            "\t//   ....[0]....\n",
            ".L_17:\n",
            "        /*0038*/ \t.word\t0x000001d0\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_INDIRECT_BRANCH_TARGETS\n",
            "\t.align\t\t4\n",
            ".L_18:\n",
            "        /*003c*/ \t.byte\t0x04, 0x34\n",
            "        /*003e*/ \t.short\t(.L_20 - .L_19)\n",
            "\n",
            "\n",
            "\t//   ....[0]....\n",
            ".L_19:\n",
            "        /*0040*/ \t.word\t.L_x_2@srel\n",
            "        /*0044*/ \t.short\t0x1\n",
            "        /*0046*/ \t.short\t0x0\n",
            "        /*0048*/ \t.word\t0x0\n",
            "\n",
            "\n",
            "\t//----- nvinfo : EIATTR_CTAIDZ_USED\n",
            "\t.align\t\t4\n",
            ".L_20:\n",
            "        /*004c*/ \t.byte\t0x01, 0x04\n",
            "\t.zero\t\t2\n",
            "\n",
            "\n",
            "//--------------------- .nv.callgraph             --------------------------\n",
            "\t.section\t.nv.callgraph,\"\",@\"SHT_CUDA_CALLGRAPH\"\n",
            "\t.align\t4\n",
            "\t.sectionentsize\t8\n",
            "\t.align\t\t4\n",
            "        /*0000*/ \t.word\t0x00000000\n",
            "\t.align\t\t4\n",
            "        /*0004*/ \t.word\t0xffffffff\n",
            "\t.align\t\t4\n",
            "        /*0008*/ \t.word\tindex@(_Z6whoamiv)\n",
            "\t.align\t\t4\n",
            "        /*000c*/ \t.word\tindex@(vprintf)\n",
            "\t.align\t\t4\n",
            "        /*0010*/ \t.word\t0x00000000\n",
            "\t.align\t\t4\n",
            "        /*0014*/ \t.word\t0xfffffffe\n",
            "\t.align\t\t4\n",
            "        /*0018*/ \t.word\t0x00000000\n",
            "\t.align\t\t4\n",
            "        /*001c*/ \t.word\t0xfffffffd\n",
            "\t.align\t\t4\n",
            "        /*0020*/ \t.word\t0x00000000\n",
            "\t.align\t\t4\n",
            "        /*0024*/ \t.word\t0xfffffffc\n",
            "\n",
            "\n",
            "//--------------------- .nv.rel.action            --------------------------\n",
            "\t.section\t.nv.rel.action,\"\",@\"SHT_CUDA_RELOCINFO\"\n",
            "\t.align\t8\n",
            "\t.sectionentsize\t8\n",
            "        /*0000*/ \t.byte\t0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x11, 0x25, 0x00, 0x05, 0x36\n",
            "\n",
            "\n",
            "//--------------------- .nv.constant4             --------------------------\n",
            "\t.section\t.nv.constant4,\"a\",@progbits\n",
            "\t.align\t8\n",
            "\t.align\t\t4\n",
            ".nv.constant4:\n",
            "        /*0000*/ \t.word\tvprintf\n",
            "\t.zero\t\t4\n",
            "\t.align\t\t8\n",
            "        /*0008*/ \t.dword\t$str\n",
            "\n",
            "\n",
            "//--------------------- .nv.constant0._Z6whoamiv  --------------------------\n",
            "\t.section\t.nv.constant0._Z6whoamiv,\"a\",@progbits\n",
            "\t.sectionflags\t@\"\"\n",
            "\t.align\t4\n",
            ".nv.constant0._Z6whoamiv:\n",
            "\t.zero\t\t320\n",
            "\n",
            "\n",
            "//--------------------- .text._Z6whoamiv          --------------------------\n",
            "\t.section\t.text._Z6whoamiv,\"ax\",@progbits\n",
            "\t.sectioninfo\t@\"SHI_REGISTERS=20\"\n",
            "\t.align\t32\n",
            "        .global         _Z6whoamiv\n",
            "        .type           _Z6whoamiv,@function\n",
            "        .size           _Z6whoamiv,(.L_x_3 - _Z6whoamiv)\n",
            "        .other          _Z6whoamiv,@\"STO_CUDA_ENTRY STV_DEFAULT\"\n",
            "_Z6whoamiv:\n",
            ".text._Z6whoamiv:\n",
            "        /*0008*/                   MOV R1, c[0x0][0x20] ;\n",
            "        /*0010*/         {         MOV R7, c[0x0][0xc] ;\n",
            "        /*0018*/                   S2R R18, SR_CTAID.Y         }\n",
            "        /*0028*/         {         IADD32I R1, R1, -0x28 ;\n",
            "        /*0030*/                   S2R R19, SR_CTAID.Z         }\n",
            "        /*0038*/         {         XMAD R0, R7.reuse, c[0x0] [0x8], RZ ;\n",
            "        /*0048*/                   S2R R14, SR_TID.Y         }\n",
            "        /*0050*/         {         XMAD.MRG R2, R7.reuse, c[0x0] [0x8].H1, RZ ;\n",
            "        /*0058*/                   S2R R15, SR_TID.Z         }\n",
            "        /*0068*/         {         XMAD.PSL.CBCC R0, R7.H1, R2.H1, R0 ;\n",
            "        /*0070*/                   S2R R3, SR_CTAID.X         }\n",
            "        /*0078*/         {         XMAD R7, R0, c[0x0] [0x10], RZ ;\n",
            "        /*0088*/                   S2R R11, SR_TID.X         }\n",
            "        /*0090*/         {         XMAD R10, R19, c[0x0] [0x18], R18 ;\n",
            "        /*0098*/                   STL.64 [R1+0x8], R18         }\n",
            "        /*00a8*/         {         XMAD.MRG R4, R19, c[0x0] [0x18].H1, RZ ;\n",
            "        /*00b0*/                   STL.64 [R1+0x18], R14         }\n",
            "        /*00b8*/                   XMAD R5, R15, c[0x0] [0xc], R14 ;\n",
            "        /*00c8*/                   XMAD.MRG R6, R15.reuse, c[0x0] [0xc].H1, RZ ;\n",
            "        /*00d0*/                   XMAD.PSL.CBCC R10, R19.H1, R4.H1, R10 ;\n",
            "        /*00d8*/                   XMAD.PSL.CBCC R2, R15.H1, R6.H1, R5 ;\n",
            "        /*00e8*/                   XMAD.MRG R6, R0, c[0x0] [0x10].H1, RZ ;\n",
            "        /*00f0*/                   MOV32I R5, 0x0 ;\n",
            "        /*00f8*/                   XMAD.MRG R13, R10, c[0x0] [0x14].H1, RZ ;\n",
            "        /*0108*/                   XMAD R12, R10.reuse, c[0x0] [0x14], R3 ;\n",
            "        /*0110*/                   XMAD.MRG R9, R2.reuse, c[0x0] [0x8].H1, RZ ;\n",
            "        /*0118*/                   XMAD R4, R2, c[0x0] [0x8], R11 ;\n",
            "        /*0128*/         {         XMAD.PSL.CBCC R7, R0.H1, R6.H1, R7 ;\n",
            "        /*0130*/                   LDC R8, c[0x4][R5]         }\n",
            "        /*0138*/                   LOP.OR R6, R1, c[0x0][0x4] ;\n",
            "        /*0148*/                   XMAD.PSL.CBCC R10, R10.H1, R13.H1, R12 ;\n",
            "        /*0150*/         {         XMAD.PSL.CBCC R0, R2.H1, R9.H1, R4 ;\n",
            "        /*0158*/                   STL.64 [R1+0x10], R10         }\n",
            "        /*0168*/         {         MOV R5, c[0x4][0xc] ;\n",
            "        /*0170*/                   STL [R1+0x20], R0         }\n",
            "        /*0178*/                   XMAD.MRG R4, R7.reuse, R10.H1.reuse, RZ ;\n",
            "        /*0188*/                   XMAD R2, R7, R10, R0 ;\n",
            "        /*0190*/                   XMAD.PSL.CBCC R2, R7.H1, R4.H1, R2 ;\n",
            "        /*0198*/         {         MOV R4, c[0x4][0x8] ;\n",
            "        /*01a8*/                   STL.64 [R1], R2         }\n",
            "        /*01b0*/                   MOV R7, RZ ;\n",
            "        /*01b8*/                   PRET `(.L_x_0) ;\n",
            ".L_x_2:\n",
            "        /*01c8*/                   JMX R8                                       (*\"INDIRECT_CALL\"*);\n",
            ".L_x_0:\n",
            "        /*01d0*/                   EXIT ;\n",
            ".L_x_1:\n",
            "        /*01d8*/                   BRA `(.L_x_1) ;\n",
            "        /*01e8*/                   NOP;\n",
            "        /*01f0*/                   NOP;\n",
            "        /*01f8*/                   NOP;\n",
            ".L_x_3:\n",
            "\n",
            "\n",
            "//--------------------- .nv.global.init           --------------------------\n",
            "\t.section\t.nv.global.init,\"aw\",@progbits\n",
            ".nv.global.init:\n",
            "\t.type\t\t$str,@object\n",
            "\t.size\t\t$str,(.L_0 - $str)\n",
            "$str:\n",
            "        /*0000*/ \t.byte\t0x25, 0x30, 0x34, 0x64, 0x20, 0x7c, 0x20, 0x42, 0x6c, 0x6f, 0x63, 0x6b, 0x28, 0x25, 0x64, 0x20\n",
            "        /*0010*/ \t.byte\t0x25, 0x64, 0x20, 0x25, 0x64, 0x29, 0x20, 0x3d, 0x20, 0x25, 0x33, 0x64, 0x20, 0x7c, 0x20, 0x54\n",
            "        /*0020*/ \t.byte\t0x68, 0x72, 0x65, 0x61, 0x64, 0x28, 0x25, 0x64, 0x20, 0x25, 0x64, 0x20, 0x25, 0x64, 0x29, 0x20\n",
            "        /*0030*/ \t.byte\t0x3d, 0x20, 0x25, 0x33, 0x64, 0x0a, 0x00\n",
            ".L_0:\n",
            "\n",
            "\n",
            "//--------------------- SYMBOLS --------------------------\n",
            "\n",
            "\t.type\t\tvprintf,@function\n"
          ]
        }
      ],
      "source": [
        "!nvcc idxing.cu -cubin -o idxing.cubin\n",
        "!nvdisasm idxing.cubin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8SBUdAkqVRx"
      },
      "outputs": [],
      "source": [
        "!nvcc -G idxing.cu -o idxing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjUCINSloxgv",
        "outputId": "db041fa7-d0aa-43be-be3d-ee56c349e56f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing thread_idx.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile thread_idx.cu\n",
        "include <stdio.h>\n",
        "\n",
        "__global__ void whoami(void) {\n",
        "    int id = threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * blockDim.x * blockDim.y;\n",
        "    printf(\"Thread in block (%d,%d,%d): id = %d\\n\", blockIdx.x, blockIdx.y, blockIdx.z, id);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    dim3 blocks(2, 2, 1);\n",
        "    dim3 threads(4, 4, 1);\n",
        "    whoami<<<blocks, threads>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd5JapiwGxRx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVX__ijhGxOa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1HTXSpaGxLR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN0f2cSCmvHV"
      },
      "outputs": [],
      "source": [
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 10000000  // Vector size = 10 million\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// Example:\n",
        "// A = [1, 2, 3, 4, 5]\n",
        "// B = [6, 7, 8, 9, 10]\n",
        "// C = A + B = [7, 9, 11, 13, 15]\n",
        "\n",
        "// CPU vector addition\n",
        "void vector_add_cpu(float *a, float *b, float *c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void vector_add_gpu(float *a, float *b, float *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Initialize vector with random values\n",
        "void init_vector(float *vec, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        vec[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to measure execution time\n",
        "double get_time() {\n",
        "    struct timespec ts;\n",
        "    clock_gettime(CLOCK_MONOTONIC, &ts);\n",
        "    return ts.tv_sec + ts.tv_nsec * 1e-9;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *h_a, *h_b, *h_c_cpu, *h_c_gpu;\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_a = (float*)malloc(size);\n",
        "    h_b = (float*)malloc(size);\n",
        "    h_c_cpu = (float*)malloc(size);\n",
        "    h_c_gpu = (float*)malloc(size);\n",
        "\n",
        "    // Initialize vectors\n",
        "    srand(time(NULL));\n",
        "    init_vector(h_a, N);\n",
        "    init_vector(h_b, N);\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    int num_blocks = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    // N = 1024, BLOCK_SIZE = 256, num_blocks = 4\n",
        "    // (N + BLOCK_SIZE - 1) / BLOCK_SIZE = ( (1025 + 256 - 1) / 256 ) = 1280 / 256 = 4 rounded\n",
        "\n",
        "    // Warm-up runs\n",
        "    printf(\"Performing warm-up runs...\\n\");\n",
        "    for (int i = 0; i < 3; i++) {\n",
        "        vector_add_cpu(h_a, h_b, h_c_cpu, N);\n",
        "        vector_add_gpu<<<num_blocks, BLOCK_SIZE>>>(d_a, d_b, d_c, N);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    // Benchmark CPU implementation\n",
        "    printf(\"Benchmarking CPU implementation...\\n\");\n",
        "    double cpu_total_time = 0.0;\n",
        "    for (int i = 0; i < 20; i++) {\n",
        "        double start_time = get_time();\n",
        "        vector_add_cpu(h_a, h_b, h_c_cpu, N);\n",
        "        double end_time = get_time();\n",
        "        cpu_total_time += end_time - start_time;\n",
        "    }\n",
        "    double cpu_avg_time = cpu_total_time / 20.0;\n",
        "\n",
        "    // Benchmark GPU implementation\n",
        "    printf(\"Benchmarking GPU implementation...\\n\");\n",
        "    double gpu_total_time = 0.0;\n",
        "    for (int i = 0; i < 20; i++) {\n",
        "        double start_time = get_time();\n",
        "        vector_add_gpu<<<num_blocks, BLOCK_SIZE>>>(d_a, d_b, d_c, N);\n",
        "        cudaDeviceSynchronize();\n",
        "        double end_time = get_time();\n",
        "        gpu_total_time += end_time - start_time;\n",
        "    }\n",
        "    double gpu_avg_time = gpu_total_time / 20.0;\n",
        "\n",
        "    // Print results\n",
        "    printf(\"CPU average time: %f milliseconds\\n\", cpu_avg_time*1000);\n",
        "    printf(\"GPU average time: %f milliseconds\\n\", gpu_avg_time*1000);\n",
        "    printf(\"Speedup: %fx\\n\", cpu_avg_time / gpu_avg_time);\n",
        "\n",
        "    // Verify results (optional)\n",
        "    cudaMemcpy(h_c_gpu, d_c, size, cudaMemcpyDeviceToHost);\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (fabs(h_c_cpu[i] - h_c_gpu[i]) > 1e-5) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Results are %s\\n\", correct ? \"correct\" : \"incorrect\");\n",
        "\n",
        "    // Free memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c_cpu);\n",
        "    free(h_c_gpu);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEWL8IbN-EBr",
        "outputId": "b728cca7-0ad5-46dc-e069-17eb5b682ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jupyterlab-lsp\n",
            "  Downloading jupyterlab_lsp-5.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab-lsp)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyterlab<5.0.0a0,>=4.1.0 (from jupyterlab-lsp)\n",
            "  Downloading jupyterlab-4.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jupyter-server>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.24.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.28.1)\n",
            "Collecting ipykernel>=6.5.0 (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (5.7.2)\n",
            "Collecting jupyter-server>=1.1.2 (from jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (24.2)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (75.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (5.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.14.0)\n",
            "Collecting comm>=0.1.1 (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (4.3.6)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp)\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (2.32.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (21.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.22.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (2.8.2)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading python_json_logger-3.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (2.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.8.4)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (24.11.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab<5.0.0a0,>=4.1.0->jupyterlab-lsp) (4.12.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading jupyterlab_lsp-5.1.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.3.5-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-3.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, json5, jedi, fqdn, comm, async-lru, jupyter-server-terminals, jupyter-client, arrow, isoduration, ipykernel, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, jupyterlab-lsp\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.4 comm-0.2.2 fqdn-1.5.1 ipykernel-6.29.5 isoduration-20.11.0 jedi-0.19.2 json5-0.10.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.5 jupyterlab-lsp-5.1.0 jupyterlab-server-2.27.3 overrides-7.7.0 python-json-logger-3.2.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n",
            "Requirement already satisfied: jupyter-lsp in /usr/local/lib/python3.11/dist-packages (2.2.5)\n",
            "Requirement already satisfied: jupyter-server>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-lsp) (2.15.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (23.1.0)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (3.1.5)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (5.7.2)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (7.7.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (24.2)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (0.21.1)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (24.0.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (0.18.1)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (5.7.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server>=1.1.2->jupyter-lsp) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server>=1.1.2->jupyter-lsp) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server>=1.1.2->jupyter-lsp) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server>=1.1.2->jupyter-lsp) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyter-server>=1.1.2->jupyter-lsp) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=7.4.4->jupyter-server>=1.1.2->jupyter-lsp) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.1.2->jupyter-lsp) (4.3.6)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (4.23.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (3.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (6.0.2)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (0.36.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (2.18.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server>=1.1.2->jupyter-lsp) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server>=1.1.2->jupyter-lsp) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (0.22.3)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (24.11.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server>=1.1.2->jupyter-lsp) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (4.12.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.1.2->jupyter-lsp) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.1.2->jupyter-lsp) (2.22)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.1.2->jupyter-lsp) (2.9.0.20241206)\n"
          ]
        }
      ],
      "source": [
        "!pip install jupyterlab-lsp\n",
        "!pip install jupyter-lsp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL2K8dYn-Nra",
        "outputId": "fb7dfa99-15c9-4000-deef-eb3be6e21165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.11/dist-packages (4.3.5)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.0.4)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (6.29.5)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (3.1.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (5.7.2)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.2.5)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.15.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (24.2)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (75.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab) (5.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab) (0.14.0)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (8.6.3)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab) (4.3.6)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (0.10.0)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.23.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.32.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.22.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (2.8.2)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.2)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.21.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.0.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.11.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (4.12.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.20241206)\n",
            "Enabling: jupyterlab\n",
            "- Writing config: /root/.jupyter\n",
            "    - Validating...\n",
            "      jupyterlab 4.3.5 \u001b[32mOK\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install jupyterlab\n",
        "!jupyter serverextension enable --py jupyterlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GhBDlR-T-NhT",
        "outputId": "a4232ece-5742-422c-9bc8-6fcfadb1e2bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mWarning: This function may stop working due to changes in browser security.\n",
            "Try `serve_kernel_port_as_iframe` instead. \u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/javascript": "(async (port, path, text, element) => {\n    if (!google.colab.kernel.accessAllowed) {\n      return;\n    }\n    element.appendChild(document.createTextNode(''));\n    const url = await google.colab.kernel.proxyPort(port);\n    const anchor = document.createElement('a');\n    anchor.href = new URL(path, url).toString();\n    anchor.target = '_blank';\n    anchor.setAttribute('data-href', url + path);\n    anchor.textContent = text;\n    element.appendChild(anchor);\n  })(8888, \"/\", \"https://localhost:8888/\", window.element)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2025-02-09 00:06:30.845 ServerApp]\u001b[m ipyparallel | extension was successfully linked.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.845 ServerApp]\u001b[m jupyter_lsp | extension was successfully linked.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.849 ServerApp]\u001b[m jupyter_server_terminals | extension was successfully linked.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.853 ServerApp]\u001b[m jupyterlab | extension was successfully linked.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'allow_root' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'allow_root' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'port_retries' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'iopub_data_rate_limit' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'iopub_msg_rate_limit' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'rate_limit_window' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'login_handler_class' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'allow_origin' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'allow_remote_access' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'disable_check_xsrf' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.855 NotebookApp]\u001b[m 'disable_check_xsrf' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
            "|DEBUG|Config changed: {'NotebookApp': {'open_browser': False, 'log_format': '|%(levelname)s|%(message)s', 'nbserver_extensions': {'jupyterlab': True}}, 'ServerApp': {'allow_root': True, 'port_retries': 0, 'iopub_data_rate_limit': 10000000000.0, 'iopub_msg_rate_limit': 10000, 'rate_limit_window': 1.0, 'login_handler_class': 'google.colab._login_handler.ColabLoginHandler', 'allow_origin': '*', 'allow_remote_access': True, 'disable_check_xsrf': True, 'port': 8888, 'ip': '0.0.0.0', 'open_browser': False, 'jpserver_extensions': <LazyConfigValue value={'jupyterlab': True, 'ipyparallel': True, 'jupyter_lsp': True, 'jupyter_server_terminals': True, 'nbclassic': True, 'notebook_shim': True, 'panel.io.jupyter_server_extension': True}>}, 'JupyterApp': {'answer_yes': True}, 'Application': {'log_level': 10}, 'MultiKernelManager': {'default_kernel_name': 'python3'}, 'Session': {'key': b'', 'keyfile': ''}, 'ExtensionApp': {'open_browser': False}}\n",
            "\u001b[33m[W 2025-02-09 00:06:30.943 ServerApp]\u001b[m ServerApp.iopub_data_rate_limit config is deprecated in 2.0. Use ZMQChannelsWebsocketConnection.iopub_data_rate_limit.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.943 ServerApp]\u001b[m ServerApp.iopub_msg_rate_limit config is deprecated in 2.0. Use ZMQChannelsWebsocketConnection.iopub_msg_rate_limit.\n",
            "\u001b[33m[W 2025-02-09 00:06:30.943 ServerApp]\u001b[m ServerApp.rate_limit_window config is deprecated in 2.0. Use ZMQChannelsWebsocketConnection.rate_limit_window.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.943 ServerApp]\u001b[m nbclassic | extension was successfully linked.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.944 ServerApp]\u001b[m Writing Jupyter server cookie secret to /root/.local/share/jupyter/runtime/jupyter_cookie_secret\n",
            "\u001b[32m[I 2025-02-09 00:06:30.947 ServerApp]\u001b[m google.colab._serverextension | extension was found and enabled by notebook_shim. Consider moving the extension to Jupyter Server's extension paths.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.947 ServerApp]\u001b[m google.colab._serverextension | extension was successfully linked.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.947 ServerApp]\u001b[m notebook_shim | extension was successfully linked.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.947 ServerApp]\u001b[m panel.io.jupyter_server_extension | extension was successfully linked.\n",
            "\u001b[34m[D 2025-02-09 00:06:30.948 ServerApp]\u001b[m Config changed: {'ExtensionApp': {'open_browser': False}, 'ZMQChannelsWebsocketConnection': {'iopub_data_rate_limit': 10000000000.0, 'iopub_msg_rate_limit': 10000.0, 'rate_limit_window': 1.0}, 'NotebookApp': {'open_browser': False, 'log_format': '|%(levelname)s|%(message)s', 'nbserver_extensions': {'jupyterlab': True}}, 'ServerApp': {'allow_root': True, 'port_retries': 0, 'iopub_data_rate_limit': 10000000000.0, 'iopub_msg_rate_limit': 10000, 'rate_limit_window': 1.0, 'login_handler_class': 'google.colab._login_handler.ColabLoginHandler', 'allow_origin': '*', 'allow_remote_access': True, 'disable_check_xsrf': True, 'port': 8888, 'ip': '0.0.0.0', 'open_browser': False, 'jpserver_extensions': <LazyConfigValue value={'jupyterlab': True, 'ipyparallel': True, 'jupyter_lsp': True, 'jupyter_server_terminals': True, 'nbclassic': True, 'notebook_shim': True, 'panel.io.jupyter_server_extension': True}>}, 'JupyterApp': {'answer_yes': True}, 'Application': {'log_level': 10}, 'MultiKernelManager': {'default_kernel_name': 'python3'}, 'Session': {'key': b'', 'keyfile': ''}}\n",
            "\u001b[33m[W 2025-02-09 00:06:30.951 ServerApp]\u001b[m Customizing authentication via ServerApp.login_handler_class=<class 'google.colab._login_handler.ColabLoginHandler'> is deprecated in Jupyter Server 2.0. Use ServerApp.identity_provider_class. Falling back on legacy authentication.\n",
            "/usr/local/lib/python3.11/dist-packages/jupyter_server/serverapp.py:2259: JupyterServerAuthWarning: Core endpoints without @allow_unauthenticated, @ws_authenticated, nor @web.authenticated:\n",
            "- GET of ColabLoginHandler registered for /login\n",
            "- POST of ColabLoginHandler registered for /login\n",
            "  self.web_app = ServerWebApplication(\n",
            "\u001b[32m[I 2025-02-09 00:06:30.965 ServerApp]\u001b[m notebook_shim | extension was successfully loaded.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.966 ServerApp]\u001b[m google.colab serverextension initialized.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.966 ServerApp]\u001b[m google.colab._serverextension | extension was successfully loaded.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.967 ServerApp]\u001b[m Loading IPython parallel extension\n",
            "\u001b[32m[I 2025-02-09 00:06:30.968 ServerApp]\u001b[m ipyparallel | extension was successfully loaded.\n",
            "\u001b[34m[D 2025-02-09 00:06:30.969 ServerApp]\u001b[m [lsp] rootUri will be file:///content\n",
            "\u001b[34m[D 2025-02-09 00:06:30.969 ServerApp]\u001b[m [lsp] virtualDocumentsUri will be file:///content/.virtual_documents\n",
            "\u001b[32m[I 2025-02-09 00:06:30.969 ServerApp]\u001b[m jupyter_lsp | extension was successfully loaded.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.970 ServerApp]\u001b[m jupyter_server_terminals | extension was successfully loaded.\n",
            "\u001b[32m[I 2025-02-09 00:06:30.981 LabApp]\u001b[m JupyterLab extension loaded from /usr/local/lib/python3.11/dist-packages/jupyterlab\n",
            "\u001b[32m[I 2025-02-09 00:06:30.981 LabApp]\u001b[m JupyterLab application directory is /usr/local/share/jupyter/lab\n",
            "\u001b[32m[I 2025-02-09 00:06:30.982 LabApp]\u001b[m Extension Manager is 'pypi'.\n",
            "\u001b[32m[I 2025-02-09 00:06:31.127 ServerApp]\u001b[m jupyterlab | extension was successfully loaded.\n",
            "\n",
            "  _   _          _      _\n",
            " | | | |_ __  __| |__ _| |_ ___\n",
            " | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "  \\___/| .__/\\__,_\\__,_|\\__\\___|\n",
            "       |_|\n",
            "                                                                           \n",
            "Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions.\n",
            "\n",
            "https://jupyter-notebook.readthedocs.io/en/latest/migrate_to_notebook7.html\n",
            "\n",
            "Please note that updating to Notebook 7 might break some of your extensions.\n",
            "\n",
            "\u001b[32m[I 2025-02-09 00:06:31.137 ServerApp]\u001b[m nbclassic | extension was successfully loaded.\n",
            "\u001b[32m[I 2025-02-09 00:06:31.137 ServerApp]\u001b[m panel.io.jupyter_server_extension | extension was successfully loaded.\n",
            "\u001b[32m[I 2025-02-09 00:06:31.138 ServerApp]\u001b[m Serving notebooks from local directory: /content\n",
            "\u001b[32m[I 2025-02-09 00:06:31.138 ServerApp]\u001b[m Jupyter Server 2.15.0 is running at:\n",
            "\u001b[32m[I 2025-02-09 00:06:31.138 ServerApp]\u001b[m http://7e5905299767:8888/lab?token=2ccf536af341e8bb69551d9b2697928619fe84e10dd1f960\n",
            "\u001b[32m[I 2025-02-09 00:06:31.138 ServerApp]\u001b[m     http://127.0.0.1:8888/lab?token=2ccf536af341e8bb69551d9b2697928619fe84e10dd1f960\n",
            "\u001b[32m[I 2025-02-09 00:06:31.138 ServerApp]\u001b[m Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
            "\u001b[35m[C 2025-02-09 00:06:31.140 ServerApp]\u001b[m \n",
            "    \n",
            "    To access the server, open this file in a browser:\n",
            "        file:///root/.local/share/jupyter/runtime/jpserver-15051-open.html\n",
            "    Or copy and paste one of these URLs:\n",
            "        http://7e5905299767:8888/lab?token=2ccf536af341e8bb69551d9b2697928619fe84e10dd1f960\n",
            "        http://127.0.0.1:8888/lab?token=2ccf536af341e8bb69551d9b2697928619fe84e10dd1f960\n",
            "\u001b[34m[D 2025-02-09 00:06:31.392 ServerApp]\u001b[m Checking for /content/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /usr/lib/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /usr/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /tools/node/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m bash-language-server/out/cli.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /content/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /usr/lib/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /usr/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m Checking for /tools/node/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.393 ServerApp]\u001b[m bash-language-server/bin/main.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /content/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /usr/lib/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /usr/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /tools/node/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m dockerfile-language-server-nodejs/lib/server.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /content/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /usr/lib/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /usr/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m Checking for /tools/node/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.394 ServerApp]\u001b[m javascript-typescript-langserver/lib/language-server-stdio.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.395 ServerApp]\u001b[m Checking for /content/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.395 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.395 ServerApp]\u001b[m Checking for /usr/lib/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.395 ServerApp]\u001b[m Checking for /usr/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.395 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.395 ServerApp]\u001b[m Checking for /tools/node/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.395 ServerApp]\u001b[m pyright/langserver.index.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.895 ServerApp]\u001b[m Checking for /content/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.895 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.895 ServerApp]\u001b[m Checking for /usr/lib/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.895 ServerApp]\u001b[m Checking for /usr/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.895 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m Checking for /tools/node/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m sql-language-server/dist/bin/cli.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m Checking for /content/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m Checking for /usr/lib/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m Checking for /usr/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m Checking for /tools/node/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:31.896 ServerApp]\u001b[m typescript-language-server/lib/cli.mjs not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /content/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/lib/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /tools/node/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m unified-language-server/src/server.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /content/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m vscode-css-languageserver-bin/cssServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /content/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.897 ServerApp]\u001b[m vscode-html-languageserver-bin/htmlServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /content/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m vscode-json-languageserver-bin/jsonServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /content/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /usr/lib/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /usr/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m Checking for /tools/node/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:31.898 ServerApp]\u001b[m yaml-language-server/bin/yaml-language-server not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[32m[I 2025-02-09 00:06:31.898 ServerApp]\u001b[m Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, python-lsp-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.004 ServerApp]\u001b[m Checking for /content/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.004 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/lib/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /tools/node/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m bash-language-server/out/cli.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /content/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/lib/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /tools/node/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m bash-language-server/bin/main.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /content/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/lib/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /tools/node/node_modules/bash-language-server/out/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m bash-language-server/out/cli.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /content/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.005 ServerApp]\u001b[m Checking for /usr/lib/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.006 ServerApp]\u001b[m Checking for /usr/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.006 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.006 ServerApp]\u001b[m Checking for /tools/node/node_modules/bash-language-server/bin/main.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.006 ServerApp]\u001b[m bash-language-server/bin/main.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.006 ServerApp]\u001b[m Checking for /content/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.006 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.006 ServerApp]\u001b[m Checking for /usr/lib/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /usr/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /tools/node/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m dockerfile-language-server-nodejs/lib/server.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /content/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /usr/lib/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /usr/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /tools/node/node_modules/dockerfile-language-server-nodejs/lib/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m dockerfile-language-server-nodejs/lib/server.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.007 ServerApp]\u001b[m Checking for /content/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /usr/lib/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /usr/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /tools/node/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m javascript-typescript-langserver/lib/language-server-stdio.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /content/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /usr/lib/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /usr/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m Checking for /tools/node/node_modules/javascript-typescript-langserver/lib/language-server-stdio.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.008 ServerApp]\u001b[m javascript-typescript-langserver/lib/language-server-stdio.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /content/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /usr/lib/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /usr/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /tools/node/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m pyright/langserver.index.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /content/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /usr/lib/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /usr/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m Checking for /tools/node/node_modules/pyright/langserver.index.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.010 ServerApp]\u001b[m pyright/langserver.index.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.013 ServerApp]\u001b[m Checking for /content/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.013 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.013 ServerApp]\u001b[m Checking for /usr/lib/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.013 ServerApp]\u001b[m Checking for /usr/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.013 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m Checking for /tools/node/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m sql-language-server/dist/bin/cli.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m Checking for /content/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m Checking for /usr/lib/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m Checking for /usr/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m Checking for /tools/node/node_modules/sql-language-server/dist/bin/cli.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.014 ServerApp]\u001b[m sql-language-server/dist/bin/cli.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /content/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /usr/lib/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /usr/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /tools/node/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m typescript-language-server/lib/cli.mjs not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /content/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.015 ServerApp]\u001b[m Checking for /usr/lib/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /usr/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /tools/node/node_modules/typescript-language-server/lib/cli.mjs\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m typescript-language-server/lib/cli.mjs not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /content/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /usr/lib/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /usr/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m Checking for /tools/node/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.016 ServerApp]\u001b[m unified-language-server/src/server.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /content/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /usr/lib/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /usr/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /tools/node/node_modules/unified-language-server/src/server.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m unified-language-server/src/server.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /content/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.017 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.018 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.018 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.018 ServerApp]\u001b[m vscode-css-languageserver-bin/cssServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.018 ServerApp]\u001b[m Checking for /content/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.018 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.100 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.100 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.100 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.100 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-css-languageserver-bin/cssServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.100 ServerApp]\u001b[m vscode-css-languageserver-bin/cssServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /content/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m vscode-html-languageserver-bin/htmlServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /content/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-html-languageserver-bin/htmlServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.101 ServerApp]\u001b[m vscode-html-languageserver-bin/htmlServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /content/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m vscode-json-languageserver-bin/jsonServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /content/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /usr/lib/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /usr/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.102 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /tools/node/node_modules/vscode-json-languageserver-bin/jsonServerMain.js\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m vscode-json-languageserver-bin/jsonServerMain.js not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /content/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /usr/lib/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /usr/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /tools/node/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m yaml-language-server/bin/yaml-language-server not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /content/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /usr/local/share/jupyter/lab/staging/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /usr/lib/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.103 ServerApp]\u001b[m Checking for /usr/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.104 ServerApp]\u001b[m Checking for /tools/node/lib/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.104 ServerApp]\u001b[m Checking for /tools/node/node_modules/yaml-language-server/bin/yaml-language-server\n",
            "\u001b[34m[D 2025-02-09 00:06:32.104 ServerApp]\u001b[m yaml-language-server/bin/yaml-language-server not found in node_modules of [PosixPath('/content'), PosixPath('/usr/local/share/jupyter/lab/staging'), PosixPath('/usr/lib'), PosixPath('/usr'), PosixPath('/tools/node/lib'), PosixPath('/tools/node')]\n",
            "\u001b[34m[D 2025-02-09 00:06:32.168 ServerApp]\u001b[m [lsp] None of the installed servers require virtual documents disabling shadow filesystem.\n",
            "\u001b[34m[D 2025-02-09 00:06:32.168 ServerApp]\u001b[m [lsp] The following Language Servers will be available: {}\n",
            "\u001b[35m[C 2025-02-09 00:13:44.885 ServerApp]\u001b[m received signal 2, stopping\n",
            "\u001b[32m[I 2025-02-09 00:13:44.885 ServerApp]\u001b[m interrupted\n",
            "\u001b[35m[C 2025-02-09 00:13:44.885 ServerApp]\u001b[m Shutting down...\n",
            "\u001b[32m[I 2025-02-09 00:13:44.886 ServerApp]\u001b[m Shutting down 8 extensions\n",
            "\u001b[32m[I 2025-02-09 00:13:44.886 ServerApp]\u001b[m Shutting down 8 extensions\n",
            "\u001b[34m[D 2025-02-09 00:13:44.886 ServerApp]\u001b[m jupyter_server_terminals | extension app 'jupyter_server_terminals' stopping\n",
            "\u001b[34m[D 2025-02-09 00:13:44.886 ServerApp]\u001b[m jupyter_server_terminals | extension app 'jupyter_server_terminals' stopped\n",
            "\u001b[34m[D 2025-02-09 00:13:44.886 ServerApp]\u001b[m jupyterlab | extension app 'lab' stopping\n",
            "\u001b[34m[D 2025-02-09 00:13:44.886 ServerApp]\u001b[m jupyterlab | extension app 'lab' stopped\n",
            "\u001b[34m[D 2025-02-09 00:13:44.886 ServerApp]\u001b[m nbclassic | extension app 'nbclassic' stopping\n",
            "\u001b[34m[D 2025-02-09 00:13:44.886 ServerApp]\u001b[m nbclassic | extension app 'nbclassic' stopped\n",
            "\u001b[34m[D 2025-02-09 00:13:44.887 ServerApp]\u001b[m jupyter_server_terminals | extension app 'jupyter_server_terminals' stopping\n",
            "\u001b[34m[D 2025-02-09 00:13:44.887 ServerApp]\u001b[m jupyter_server_terminals | extension app 'jupyter_server_terminals' stopped\n",
            "\u001b[34m[D 2025-02-09 00:13:44.887 ServerApp]\u001b[m jupyterlab | extension app 'lab' stopping\n",
            "\u001b[34m[D 2025-02-09 00:13:44.887 ServerApp]\u001b[m jupyterlab | extension app 'lab' stopped\n",
            "\u001b[34m[D 2025-02-09 00:13:44.887 ServerApp]\u001b[m nbclassic | extension app 'nbclassic' stopping\n",
            "\u001b[34m[D 2025-02-09 00:13:44.887 ServerApp]\u001b[m nbclassic | extension app 'nbclassic' stopped\n"
          ]
        }
      ],
      "source": [
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(8888)\n",
        "!jupyter lab --port=8888 --no-browser --ip=0.0.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyUhsE5GmvEp",
        "outputId": "8fca6756-942c-44df-a1fc-034898c76157"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: unrecognized arguments: --language vector_add.cu\n"
          ]
        }
      ],
      "source": [
        "# @title Texto de título predeterminado\n",
        "\n",
        "%%writefile vector_add.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 10000000  // Vector size = 10 million\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// Example:\n",
        "// A = [1, 2, 3, 4, 5]\n",
        "// B = [6, 7, 8, 9, 10]\n",
        "// C = A + B = [7, 9, 11, 13, 15]\n",
        "\n",
        "// CPU vector addition\n",
        "\n",
        "void vector_add_cpu(float *a, float *b, float *c, int n) {\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    c[i] = a[i] + b[i]; //what we looked at b4\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// cuda kernel for vector addition\n",
        "\n",
        "__global__ void vector_add_gpu(float *a, float *b, float *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {            // instead of having a forloop, what were doing here is unrolling this loop\n",
        "        c[i] = a[i] + b[i]; // and distribuiting them across different blocks, parallelizing the operation and distribuiting them separately ]\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "//init our vector\n",
        "\n",
        "void init_vector(float *vec, int n) {\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    vec[i] = (float)rand() / RAND_MAX;\n",
        "  }\n",
        "}\n",
        "\n",
        "// Function to measure execution time - to benchmark perf\n",
        "\n",
        "\n",
        "double get_time() {\n",
        "    struct timespec ts;\n",
        "    clock_gettime(CLOCK_MONOTONIC, &ts);\n",
        "    return ts.tv_sec + ts.tv_nsec * 1e-9;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *h_a, *h_b, *h_c_cpu, *h_c_gpu;\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_a = (float*)malloc(size);\n",
        "    h_b = (float*)malloc(size);\n",
        "    h_c_cpu = (float*)malloc(size);\n",
        "    h_c_gpu = (float*)malloc(size);\n",
        "\n",
        "    // Initialize vectors\n",
        "    srand(time(NULL));\n",
        "    init_vector(h_a, N);\n",
        "    init_vector(h_b, N);\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&d_a, size); // device pointer, memry address\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice); // CPU moving to GPU\n",
        "\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    int num_blocks = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    // N = 1024, BLOCK_SIZE = 256, num_blocks = 4\n",
        "    // (N + BLOCK_SIZE - 1) / BLOCK_SIZE = ( (1025 + 256 - 1) / 256 ) = 1280 / 256 = 4 rounded\n",
        "\n",
        "    // Warm-up runs\n",
        "    printf(\"Performing warm-up runs...\\n\");\n",
        "    for (int i = 0; i < 3; i++) {\n",
        "        vector_add_cpu(h_a, h_b, h_c_cpu, N);\n",
        "        vector_add_gpu<<<num_blocks, BLOCK_SIZE>>>(d_a, d_b, d_c, N);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    // Benchmark CPU implementation\n",
        "    printf(\"Benchmarking CPU implementation...\\n\");\n",
        "    double cpu_total_time = 0.0;\n",
        "    for (int i = 0; i < 20; i++) {\n",
        "        double start_time = get_time();\n",
        "        vector_add_cpu(h_a, h_b, h_c_cpu, N);\n",
        "        double end_time = get_time();\n",
        "        cpu_total_time += end_time - start_time;\n",
        "    }\n",
        "    double cpu_avg_time = cpu_total_time / 20.0;\n",
        "\n",
        "    // Benchmark GPU implementation\n",
        "    printf(\"Benchmarking GPU implementation...\\n\");\n",
        "    double gpu_total_time = 0.0;\n",
        "    for (int i = 0; i < 20; i++) {\n",
        "        double start_time = get_time();\n",
        "        vector_add_gpu<<<num_blocks, BLOCK_SIZE>>>(d_a, d_b, d_c, N);\n",
        "        cudaDeviceSynchronize();\n",
        "        double end_time = get_time();\n",
        "        gpu_total_time += end_time - start_time;\n",
        "    }\n",
        "    double gpu_avg_time = gpu_total_time / 20.0;\n",
        "\n",
        "    // Print results\n",
        "    printf(\"CPU average time: %f milliseconds\\n\", cpu_avg_time*1000);\n",
        "    printf(\"GPU average time: %f milliseconds\\n\", gpu_avg_time*1000);\n",
        "    printf(\"Speedup: %fx\\n\", cpu_avg_time / gpu_avg_time);\n",
        "\n",
        "    // Verify results (optional)\n",
        "    cudaMemcpy(h_c_gpu, d_c, size, cudaMemcpyDeviceToHost);\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (fabs(h_c_cpu[i] - h_c_gpu[i]) > 1e-5) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    printf(\"Results are %s\\n\", correct ? \"correct\" : \"incorrect\");\n",
        "\n",
        "    // Free memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c_cpu);\n",
        "    free(h_c_gpu);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4EbF3ClmvB5"
      },
      "outputs": [],
      "source": [
        "!nvcc vector_add.cu -o vector_add\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUJKYRp4mu-8",
        "outputId": "574a9c0c-1856-4f15-9964-68ddc003482e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing warm-up runs...\n",
            "Benchmarking CPU implementation...\n",
            "Benchmarking GPU implementation...\n",
            "CPU average time: 33.201688 milliseconds\n",
            "GPU average time: 0.002372 milliseconds\n",
            "Speedup: 13995.273745x\n",
            "Results are incorrect\n"
          ]
        }
      ],
      "source": [
        "!./vector_add\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALujYye7mu7v",
        "outputId": "24c5f1ed-3d46-4c2b-9863-99716c827f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing vector_add.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_add.cpp\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <math.h>\n",
        "\n",
        "#define N 10000000  // Vector size = 10 million\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// Macro for error checking\n",
        "#define cudaCheckError(call) {                                     \\\n",
        "    cudaError_t err = call;                                        \\\n",
        "    if (err != cudaSuccess) {                                      \\\n",
        "        fprintf(stderr, \"CUDA error in %s at %s:%d: %s\\n\",         \\\n",
        "                #call, __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "        exit(err);                                                 \\\n",
        "    }                                                              \\\n",
        "}\n",
        "\n",
        "// CPU vector addition\n",
        "void vector_add_cpu(float *a, float *b, float *c, int n) {\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    c[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void vector_add_gpu(float *a, float *b, float *c, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;  // how many threads are there / block * no. of blocks\n",
        "    if (i < n) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Initialize vector with random float values between 0 and 1\n",
        "void init_vector(float *vec, int n) {\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    vec[i] = (float)rand() / RAND_MAX;\n",
        "  }\n",
        "}\n",
        "\n",
        "// Function to get the current time in seconds (for benchmarking)\n",
        "double get_time() {\n",
        "    struct timespec ts;\n",
        "    clock_gettime(CLOCK_MONOTONIC, &ts);\n",
        "    return ts.tv_sec + ts.tv_nsec * 1e-9;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *h_a, *h_b, *h_c_cpu, *h_c_gpu;\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_a = (float*)malloc(size);\n",
        "    h_b = (float*)malloc(size);\n",
        "    h_c_cpu = (float*)malloc(size);\n",
        "    h_c_gpu = (float*)malloc(size);\n",
        "\n",
        "    // Initialize vectors\n",
        "    srand(time(NULL));\n",
        "    init_vector(h_a, N);\n",
        "    init_vector(h_b, N);\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaCheckError(cudaMalloc(&d_a, size));\n",
        "    cudaCheckError(cudaMalloc(&d_b, size));\n",
        "    cudaCheckError(cudaMalloc(&d_c, size));\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaCheckError(cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice));\n",
        "    cudaCheckError(cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    int num_blocks = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "\n",
        "    // Warm-up runs\n",
        "    printf(\"Performing warm-up runs...\\n\");\n",
        "    for (int i = 0; i < 3; i++) {\n",
        "        vector_add_cpu(h_a, h_b, h_c_cpu, N);\n",
        "        vector_add_gpu<<<num_blocks, BLOCK_SIZE>>>(d_a, d_b, d_c, N);\n",
        "        cudaCheckError(cudaGetLastError());\n",
        "        cudaCheckError(cudaDeviceSynchronize());\n",
        "    }\n",
        "\n",
        "    // Benchmark CPU implementation\n",
        "    printf(\"Benchmarking CPU implementation...\\n\");\n",
        "    double cpu_total_time = 0.0;\n",
        "    for (int i = 0; i < 20; i++) {\n",
        "        double start_time = get_time();\n",
        "        vector_add_cpu(h_a, h_b, h_c_cpu, N);\n",
        "        double end_time = get_time();\n",
        "        cpu_total_time += end_time - start_time;\n",
        "    }\n",
        "    double cpu_avg_time = cpu_total_time / 20.0;\n",
        "\n",
        "    // Benchmark GPU implementation\n",
        "    printf(\"Benchmarking GPU implementation...\\n\");\n",
        "    double gpu_total_time = 0.0;\n",
        "    for (int i = 0; i < 20; i++) {\n",
        "        // (Optional) re-copy inputs if needed\n",
        "        // cudaCheckError(cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice));\n",
        "        // cudaCheckError(cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "        double start_time = get_time();\n",
        "        vector_add_gpu<<<num_blocks, BLOCK_SIZE>>>(d_a, d_b, d_c, N);\n",
        "        cudaCheckError(cudaGetLastError());\n",
        "        cudaCheckError(cudaDeviceSynchronize());\n",
        "        double end_time = get_time();\n",
        "        gpu_total_time += end_time - start_time;\n",
        "    }\n",
        "    double gpu_avg_time = gpu_total_time / 20.0;\n",
        "\n",
        "    // Copy GPU result back to host\n",
        "    cudaCheckError(cudaMemcpy(h_c_gpu, d_c, size, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Print a few sample values for comparison\n",
        "    printf(\"First 10 elements:\\n\");\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"Index %d: CPU = %f, GPU = %f\\n\", i, h_c_cpu[i], h_c_gpu[i]);\n",
        "    }\n",
        "\n",
        "    // Verify results\n",
        "    bool correct = true;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (fabs(h_c_cpu[i] - h_c_gpu[i]) > 1e-5) {\n",
        "            correct = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    printf(\"CPU average time: %f milliseconds\\n\", cpu_avg_time * 1000);\n",
        "    printf(\"GPU average time: %f milliseconds\\n\", gpu_avg_time * 1000);\n",
        "    printf(\"Speedup: %fx\\n\", cpu_avg_time / gpu_avg_time);\n",
        "    printf(\"Results are %s\\n\", correct ? \"correct\" : \"incorrect\");\n",
        "\n",
        "    // Free memory\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c_cpu);\n",
        "    free(h_c_gpu);\n",
        "    cudaCheckError(cudaFree(d_a));\n",
        "    cudaCheckError(cudaFree(d_b));\n",
        "    cudaCheckError(cudaFree(d_c));\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbuA3j3zHdIY"
      },
      "outputs": [],
      "source": [
        "!mv vector_add.cpp vector_add.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPvTaK0Pmu5N"
      },
      "outputs": [],
      "source": [
        "!nvcc -gencode arch=compute_80,code=sm_80 vector_add.cu -o vector_add\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0j9wSj_t7dc"
      },
      "source": [
        "!nvcc -gencode arch=compute_80,code=sm_80 vector_add.cu -o vector_add\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPIzUIVemu2X",
        "outputId": "212653f9-b1f0-45ec-fc31-6336d5768ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing warm-up runs...\n",
            "Benchmarking CPU implementation...\n",
            "Benchmarking GPU implementation...\n",
            "First 10 elements:\n",
            "Index 0: CPU = 0.873982, GPU = 0.873982\n",
            "Index 1: CPU = 1.092135, GPU = 1.092135\n",
            "Index 2: CPU = 0.329347, GPU = 0.329347\n",
            "Index 3: CPU = 1.244920, GPU = 1.244920\n",
            "Index 4: CPU = 0.121245, GPU = 0.121245\n",
            "Index 5: CPU = 0.936237, GPU = 0.936237\n",
            "Index 6: CPU = 1.370975, GPU = 1.370975\n",
            "Index 7: CPU = 1.169952, GPU = 1.169952\n",
            "Index 8: CPU = 1.097276, GPU = 1.097276\n",
            "Index 9: CPU = 1.400032, GPU = 1.400032\n",
            "CPU average time: 33.354476 milliseconds\n",
            "GPU average time: 0.101068 milliseconds\n",
            "Speedup: 330.019491x\n",
            "Results are correct\n"
          ]
        }
      ],
      "source": [
        "!./vector_add\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFtnnu81ql5S"
      },
      "source": [
        "### Naive Matmul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds9UVqXKmuzl",
        "outputId": "3df807a8-f9d5-42b0-b7b5-712a151703a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing matmul.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile matmul.cpp\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define M 256  // Number of rows in A and C\n",
        "#define K 512   // Number of columns in A and rows in B\n",
        "#define N 256  // Number of columns in B and C\n",
        "#define BLOCK_SIZE 32\n",
        "\n",
        "// Example 3x2 @ 2x4 = 3x4 -> (M x K) @ (K x N) = (M x N)\n",
        "// A = [[1, 2],\n",
        "//      [3, 4],\n",
        "//      [5, 6]]\n",
        "\n",
        "// B = [[7, 8, 9, 10],\n",
        "//      [11, 12, 13, 14]]\n",
        "\n",
        "// C = A * B = [[1*7 + 2*11, 1*8 + 2*12, 1*9 + 2*13, 1*10 + 2*14],\n",
        "//              [3*7 + 4*11, 3*8 + 4*12, 3*9 + 4*13, 3*10 + 4*14],\n",
        "//              [5*7 + 6*11, 5*8 + 6*12, 5*9 + 6*13, 5*10 + 6*14]]\n",
        "\n",
        "// C = [[29, 32, 35, 38],\n",
        "//      [65, 72, 79, 86],\n",
        "//      [101, 112, 123, 134]]\n",
        "\n",
        "\n",
        "// CPU matrix multiplication\n",
        "void matmul_cpu(float *A, float *B, float *C, int m, int k, int n) {\n",
        "    for (int i = 0; i < m; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            float sum = 0.0f;\n",
        "            for (int l = 0; l < k; l++) {\n",
        "                sum += A[i * k + l] * B[l * n + j];\n",
        "            }\n",
        "            C[i * n + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA kernel for matrix multiplication\n",
        "__global__ void matmul_gpu(float *A, float *B, float *C, int m, int k, int n) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < m && col < n) {\n",
        "        float sum = 0.0f;\n",
        "        for (int l = 0; l < k; l++) {\n",
        "            sum += A[row * k + l] * B[l * n + col];\n",
        "        }\n",
        "        C[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Initialize matrix with random values\n",
        "void init_matrix(float *mat, int rows, int cols) {\n",
        "    for (int i = 0; i < rows * cols; i++) {\n",
        "        mat[i] = (float)rand() / RAND_MAX;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to measure execution time\n",
        "double get_time() {\n",
        "    struct timespec ts;\n",
        "    clock_gettime(CLOCK_MONOTONIC, &ts);\n",
        "    return ts.tv_sec + ts.tv_nsec * 1e-9;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *h_A, *h_B, *h_C_cpu, *h_C_gpu;\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    int size_A = M * K * sizeof(float);\n",
        "    int size_B = K * N * sizeof(float);\n",
        "    int size_C = M * N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_A = (float*)malloc(size_A);\n",
        "    h_B = (float*)malloc(size_B);\n",
        "    h_C_cpu = (float*)malloc(size_C);\n",
        "    h_C_gpu = (float*)malloc(size_C);\n",
        "\n",
        "    // Initialize matrices\n",
        "    srand(time(NULL));\n",
        "    init_matrix(h_A, M, K);\n",
        "    init_matrix(h_B, K, N);\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&d_A, size_A);\n",
        "    cudaMalloc(&d_B, size_B);\n",
        "    cudaMalloc(&d_C, size_C);\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaMemcpy(d_A, h_A, size_A, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size_B, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 blockDim(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 gridDim((N + BLOCK_SIZE - 1) / BLOCK_SIZE, (M + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "\n",
        "    // Warm-up runs\n",
        "    printf(\"Performing warm-up runs...\\n\");\n",
        "    for (int i = 0; i < 3; i++) {\n",
        "        matmul_cpu(h_A, h_B, h_C_cpu, M, K, N);\n",
        "        matmul_gpu<<<gridDim, blockDim>>>(d_A, d_B, d_C, M, K, N);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    // Benchmark CPU implementation\n",
        "    printf(\"Benchmarking CPU implementation...\\n\");\n",
        "    double cpu_total_time = 0.0;\n",
        "    for (int i = 0; i < 20; i++) {\n",
        "        double start_time = get_time();\n",
        "        matmul_cpu(h_A, h_B, h_C_cpu, M, K, N);\n",
        "        double end_time = get_time();\n",
        "        cpu_total_time += end_time - start_time;\n",
        "    }\n",
        "    double cpu_avg_time = cpu_total_time / 20.0;\n",
        "\n",
        "    // Benchmark GPU implementation\n",
        "    printf(\"Benchmarking GPU implementation...\\n\");\n",
        "    double gpu_total_time = 0.0;\n",
        "    for (int i = 0; i < 20; i++) {\n",
        "        double start_time = get_time();\n",
        "        matmul_gpu<<<gridDim, blockDim>>>(d_A, d_B, d_C, M, K, N);\n",
        "        cudaDeviceSynchronize();\n",
        "        double end_time = get_time();\n",
        "        gpu_total_time += end_time - start_time;\n",
        "    }\n",
        "    double gpu_avg_time = gpu_total_time / 20.0;\n",
        "\n",
        "    // Print results\n",
        "    printf(\"CPU average time: %f microseconds\\n\", (cpu_avg_time * 1e6f));\n",
        "    printf(\"GPU average time: %f microseconds\\n\", (gpu_avg_time * 1e6f));\n",
        "    printf(\"Speedup: %fx\\n\", cpu_avg_time / gpu_avg_time);\n",
        "\n",
        "    // Free memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C_cpu);\n",
        "    free(h_C_gpu);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilM9NCYmmuw3"
      },
      "outputs": [],
      "source": [
        "!mv matmul.cpp matmul.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAiRFKh2muuV"
      },
      "outputs": [],
      "source": [
        "!nvcc -gencode arch=compute_80,code=sm_80 matmul.cu -o matmul\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xla6EvFsmuro",
        "outputId": "98bddacd-3745-4db0-cf1e-b0bba4144520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing warm-up runs...\n",
            "Benchmarking CPU implementation...\n",
            "Benchmarking GPU implementation...\n",
            "CPU average time: 138633.033650 microseconds\n",
            "GPU average time: 52.540550 microseconds\n",
            "Speedup: 2638.591214x\n"
          ]
        }
      ],
      "source": [
        "!./matmul\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wg6BR1fmuo1",
        "outputId": "e712822c-6c0b-4a3a-ecaf-2e052d0a9344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing t_matmul.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile t_matmul.cpp\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "#define TILE_SIZE 16\n",
        "\n",
        "__global__ void matrixMultiplyOptimized(float* A, float* B, float* C, int M, int N, int K) {\n",
        "    __shared__ float sharedA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float sharedB[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    int bx = blockIdx.x, by = blockIdx.y;\n",
        "    int tx = threadIdx.x, ty = threadIdx.y;\n",
        "\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    for (int tile = 0; tile < (K + TILE_SIZE - 1) / TILE_SIZE; ++tile) {\n",
        "        if (row < M && tile * TILE_SIZE + tx < K)\n",
        "            sharedA[ty][tx] = A[row * K + tile * TILE_SIZE + tx];\n",
        "        else\n",
        "            sharedA[ty][tx] = 0.0f;\n",
        "\n",
        "        if (col < N && tile * TILE_SIZE + ty < K)\n",
        "            sharedB[ty][tx] = B[(tile * TILE_SIZE + ty) * N + col];\n",
        "        else\n",
        "            sharedB[ty][tx] = 0.0f;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_SIZE; ++k)\n",
        "            sum += sharedA[ty][k] * sharedB[k][tx];\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (row < M && col < N)\n",
        "        C[row * N + col] = sum;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Define matrix dimensions\n",
        "    const int M = 1024; // Number of rows in A and C\n",
        "    const int N = 1024; // Number of columns in B and C\n",
        "    const int K = 1024; // Number of columns in A and rows in B\n",
        "\n",
        "    // Calculate matrix sizes in bytes\n",
        "    size_t size_A = M * K * sizeof(float);\n",
        "    size_t size_B = K * N * sizeof(float);\n",
        "    size_t size_C = M * N * sizeof(float);\n",
        "\n",
        "    // Declare device pointers\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc(&d_A, size_A);\n",
        "    cudaMalloc(&d_B, size_B);\n",
        "    cudaMalloc(&d_C, size_C);\n",
        "\n",
        "\n",
        "    // Kernel launch code\n",
        "    dim3 blockDim(TILE_SIZE, TILE_SIZE);\n",
        "    dim3 gridDim((N + TILE_SIZE - 1) / TILE_SIZE, (M + TILE_SIZE - 1) / TILE_SIZE);\n",
        "    matrixMultiplyOptimized<<<gridDim, blockDim>>>(d_A, d_B, d_C, M, N, K);\n",
        "\n",
        "    // Synchronize device\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    // Check for any CUDA errors\n",
        "    cudaError_t error = cudaGetLastError();\n",
        "    if (error != cudaSuccess) {\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(error) << std::endl;\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_wA2oJj5Hyt",
        "outputId": "12ee991b-1840-4032-f6b4-d76b3b209ae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting nvtx_matmul.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile nvtx_matmul.cpp\n",
        "#include <cuda_runtime.h>\n",
        "#include <nvtx3/nvToolsExt.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "__global__ void matrixMulKernel(float* A, float* B, float* C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            sum += A[row * N + i] * B[i * N + col];\n",
        "        }\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matrixMul(float* A, float* B, float* C, int N) {\n",
        "    nvtxRangePush(\"Matrix Multiplication\");\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    int size = N * N * sizeof(float);\n",
        "\n",
        "    nvtxRangePush(\"Memory Allocation\");\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "    nvtxRangePop();\n",
        "\n",
        "    nvtxRangePush(\"Memory Copy H2D\");\n",
        "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "    nvtxRangePop();\n",
        "\n",
        "    dim3 threadsPerBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 numBlocks((N + BLOCK_SIZE - 1) / BLOCK_SIZE, (N + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "    // timing code\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "    nvtxRangePush(\"Kernel Execution\");\n",
        "    cudaEventRecord(start);\n",
        "    matrixMulKernel<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaDeviceSynchronize();\n",
        "    nvtxRangePop();\n",
        "\n",
        "    // Calculate elapsed time\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    std::cout << \"Kernel execution time: \" << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "    // Clean up events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "\n",
        "    nvtxRangePush(\"Memory Copy D2H\");\n",
        "    cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    nvtxRangePop();\n",
        "\n",
        "    nvtxRangePush(\"Memory Deallocation\");\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    nvtxRangePop();\n",
        "\n",
        "    nvtxRangePop();  // End of Matrix Multiplication\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1024;\n",
        "    float *A = new float[N*N];\n",
        "    float *B = new float[N*N];\n",
        "    float *C = new float[N*N];\n",
        "\n",
        "    // Initialize matrices A and B (for example, fill with 1.0f)\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        A[i] = 1.0f;\n",
        "        B[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    matrixMul(A, B, C, N);\n",
        "\n",
        "    // (Optional) Check one value from C\n",
        "    std::cout << \"C[0] = \" << C[0] << std::endl;\n",
        "\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzAU0V1ghM6q",
        "outputId": "3db2c96b-1fff-42dd-fb70-2ca01a4b8d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing nvtx_matmul.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile nvtx_matmul.cpp\n",
        "#include <cuda_runtime.h>\n",
        "#include <nvtx3/nvToolsExt.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "// Naive matrix multiplication kernel (same as your original)\n",
        "__global__ void matrixMulKernelNaive(float* A, float* B, float* C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            sum += A[row * N + i] * B[i * N + col];\n",
        "        }\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Optimized matrix multiplication kernel using tiling and shared memory\n",
        "__global__ void matrixMulKernelOptimized(float* A, float* B, float* C, int N) {\n",
        "    __shared__ float tileA[BLOCK_SIZE][BLOCK_SIZE];\n",
        "    __shared__ float tileB[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\n",
        "    int row = blockIdx.y * BLOCK_SIZE + threadIdx.y;\n",
        "    int col = blockIdx.x * BLOCK_SIZE + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Loop over tiles\n",
        "    for (int m = 0; m < (N + BLOCK_SIZE - 1) / BLOCK_SIZE; m++) {\n",
        "        // Load elements into shared memory\n",
        "        if (row < N && m * BLOCK_SIZE + threadIdx.x < N)\n",
        "            tileA[threadIdx.y][threadIdx.x] = A[row * N + m * BLOCK_SIZE + threadIdx.x];\n",
        "        else\n",
        "            tileA[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        if (col < N && m * BLOCK_SIZE + threadIdx.y < N)\n",
        "            tileB[threadIdx.y][threadIdx.x] = B[(m * BLOCK_SIZE + threadIdx.y) * N + col];\n",
        "        else\n",
        "            tileB[threadIdx.y][threadIdx.x] = 0.0f;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        // Multiply the two tiles\n",
        "        for (int k = 0; k < BLOCK_SIZE; k++) {\n",
        "            sum += tileA[threadIdx.y][k] * tileB[k][threadIdx.x];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matrixMul(float* A, float* B, float* C, int N) {\n",
        "    nvtxRangePush(\"Matrix Multiplication\");\n",
        "\n",
        "    float *d_A, *d_B, *d_C_naive, *d_C_opt;\n",
        "    int size = N * N * sizeof(float);\n",
        "\n",
        "    nvtxRangePush(\"Memory Allocation\");\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C_naive, size);\n",
        "    cudaMalloc(&d_C_opt, size);\n",
        "    nvtxRangePop();\n",
        "\n",
        "    nvtxRangePush(\"Memory Copy H2D\");\n",
        "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
        "    nvtxRangePop();\n",
        "\n",
        "    dim3 threadsPerBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 numBlocks((N + BLOCK_SIZE - 1) / BLOCK_SIZE, (N + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "\n",
        "    // ----- Naive Kernel Execution -----\n",
        "    cudaEvent_t startNaive, stopNaive;\n",
        "    cudaEventCreate(&startNaive);\n",
        "    cudaEventCreate(&stopNaive);\n",
        "\n",
        "    nvtxRangePush(\"Naive Kernel Execution\");\n",
        "    cudaEventRecord(startNaive);\n",
        "    matrixMulKernelNaive<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C_naive, N);\n",
        "    cudaEventRecord(stopNaive);\n",
        "    cudaDeviceSynchronize();\n",
        "    nvtxRangePop();\n",
        "\n",
        "    float naiveTime = 0;\n",
        "    cudaEventElapsedTime(&naiveTime, startNaive, stopNaive);\n",
        "    std::cout << \"Naive Kernel execution time: \" << naiveTime << \" ms\" << std::endl;\n",
        "    cudaEventDestroy(startNaive);\n",
        "    cudaEventDestroy(stopNaive);\n",
        "\n",
        "    // ----- Optimized Kernel Execution -----\n",
        "    cudaEvent_t startOpt, stopOpt;\n",
        "    cudaEventCreate(&startOpt);\n",
        "    cudaEventCreate(&stopOpt);\n",
        "\n",
        "    nvtxRangePush(\"Optimized Kernel Execution\");\n",
        "    cudaEventRecord(startOpt);\n",
        "    matrixMulKernelOptimized<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C_opt, N);\n",
        "    cudaEventRecord(stopOpt);\n",
        "    cudaDeviceSynchronize();\n",
        "    nvtxRangePop();\n",
        "\n",
        "    float optTime = 0;\n",
        "    cudaEventElapsedTime(&optTime, startOpt, stopOpt);\n",
        "    std::cout << \"Optimized Kernel execution time: \" << optTime << \" ms\" << std::endl;\n",
        "    cudaEventDestroy(startOpt);\n",
        "    cudaEventDestroy(stopOpt);\n",
        "\n",
        "    // Copy one result (here, from the optimized kernel) back to host\n",
        "    nvtxRangePush(\"Memory Copy D2H\");\n",
        "    cudaMemcpy(C, d_C_opt, size, cudaMemcpyDeviceToHost);\n",
        "    nvtxRangePop();\n",
        "\n",
        "    nvtxRangePush(\"Memory Deallocation\");\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C_naive);\n",
        "    cudaFree(d_C_opt);\n",
        "    nvtxRangePop();\n",
        "\n",
        "    nvtxRangePop();  // End of Matrix Multiplication\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 1024;\n",
        "    float *A = new float[N * N];\n",
        "    float *B = new float[N * N];\n",
        "    float *C = new float[N * N];\n",
        "\n",
        "    // Initialize matrices A and B (for example, fill with 1.0f)\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        A[i] = 1.0f;\n",
        "        B[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    matrixMul(A, B, C, N);\n",
        "\n",
        "    // (Optional) Check one value from C (result from optimized kernel)\n",
        "    std::cout << \"C[0] = \" << C[0] << std::endl;\n",
        "\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGVOeq1veqnE"
      },
      "outputs": [],
      "source": [
        "!mv nvtx_matmul.cpp nvtx_matmul.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv5sLp5yZf_k"
      },
      "outputs": [],
      "source": [
        "!nvcc -O3 -o nvtx_matmul nvtx_matmul.cu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QopvFWoZf82",
        "outputId": "937c5cae-6e38-44ba-9749-87fffe8c9576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Kernel execution time: 8.23997 ms\n",
            "Optimized Kernel execution time: 0.00384 ms\n",
            "C[0] = 0\n"
          ]
        }
      ],
      "source": [
        "!./nvtx_matmul\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odqmHkhbkcPw",
        "outputId": "486ed9d5-96fd-475e-ef05-4dbdac0859c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing tile_matmul1.cpp\n"
          ]
        }
      ],
      "source": [
        "## Now let me try and write out the kernels myself (well w a bit of help 😅)\n",
        "\n",
        "%%writefile tile_matmul1.cpp\n",
        "#include <cuda_runtime.h>\n",
        "#include <nvtx3/nvToolsExt.h>\n",
        "#include <iostream>\n",
        "\n",
        "\n",
        "__global__ void tiled_sq_matmul(float* A, float* B, float* C,  int N)\n",
        "{\n",
        "\n",
        "  // Defining local variables regardubg this thread\n",
        "    int by = blockIdx.y;\n",
        "    int bx = blockIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "\n",
        "    // Output matrix C[i,j]\n",
        "\n",
        "    int i = blockDim.y*by + ty;\n",
        "    int j = blockDim.x*bx + tx;\n",
        "\n",
        "    // Allocating shared memory\n",
        "    __shared__ float sh_A[TILE_WIDTH][TILE_WIDTH]\n",
        "    __shared__ float sh_B[TILE_WIDTH][TILE_WIDTH]\n",
        "\n",
        "    // Parallel mat mul\n",
        "    float value = 0;\n",
        "    // Splitting data into smaller tiles\n",
        "    for (int phase = 0; N/TILE_WIDTH; phase++)\n",
        "    {\n",
        "      // load tiles into shared memory\n",
        "      sh_A[ty][tx] = A[(i)*N+phase*TILE_WIDTH+tx];\n",
        "      sh_B[ty][tx] = B[(phase*TILE_WIDTH +ty)*N+J];\n",
        "      __syncthreads(); // ensuring all threads finish at the same time\n",
        "      // Dot product is performed with elements on the shared memory\n",
        "      for (int k =0; k < TILE_WIDTH; k++)\n",
        "        value += sh_A[ty][k] * sh_B[k][tx];\n",
        "      __syncthreads(); // ensuring all threads finish at the same time\n",
        "    }\n",
        "\n",
        "    // Storing result in Matrix C\n",
        "    C[i*N+j] = value;\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAulapxkkcNQ"
      },
      "outputs": [],
      "source": [
        "!mv tile_matmul1.cpp tile_matmul1.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1_aTxgdZf5z",
        "outputId": "322583ab-305e-4b7b-9583-5d4776cea57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mtile_matmul1.cu(21)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mTILE_WIDTH\u001b[0m\" is undefined\n",
            "      __attribute__((shared)) float sh_A[TILE_WIDTH][TUKE_WIDTH]\n",
            "                                         ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mtile_matmul1.cu(21)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mTUKE_WIDTH\u001b[0m\" is undefined\n",
            "      __attribute__((shared)) float sh_A[TILE_WIDTH][TUKE_WIDTH]\n",
            "                                                     ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mtile_matmul1.cu(22)\u001b[0m: \u001b[01;31merror\u001b[0m: expected a \";\"\n",
            "      __attribute__((shared)) float sh_B[TILE_WIDTH][TUKE_WIDTH]\n",
            "                              ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mtile_matmul1.cu(25)\u001b[0m: \u001b[01;35mwarning\u001b[0m #12-D: parsing restarts here after previous syntax error\n",
            "      float value = 0;\n",
            "                     ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mtile_matmul1.cu(31)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01msh_B\u001b[0m\" is undefined\n",
            "        sh_B[ty][tx] = B[(phase*TILE_WIDTH +ty)*N+J];\n",
            "        ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mtile_matmul1.cu(31)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mJ\u001b[0m\" is undefined\n",
            "        sh_B[ty][tx] = B[(phase*TILE_WIDTH +ty)*N+J];\n",
            "                                                  ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mtile_matmul1.cu(35)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mvalue\u001b[0m\" is undefined\n",
            "          value += sh_A[ty][k] * sh_B[k][tx];\n",
            "          ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mtile_matmul1.cu(40)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mvalue\u001b[0m\" is undefined\n",
            "      C[i*N+j] = value;\n",
            "                 ^\n",
            "\n",
            "7 errors detected in the compilation of \"tile_matmul1.cu\".\n"
          ]
        }
      ],
      "source": [
        "!nvcc -O3 -o tile_matmul1 tile_matmul1.cu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKniInHKrHWp"
      },
      "outputs": [],
      "source": [
        "%%writefile t_mm2.cpp\n",
        "#include <cuda_runtime.h>\n",
        "#include <nvtx3/nvToolsExt.h>\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "\n",
        "\n",
        "__global__ void tiled_sqr_matmul()\n",
        "{\n",
        "  for(int i = 0; i < N * N; i++)\n",
        "  {\n",
        "      m[i] = rand() % 100; // this will give us rand nums > 100\n",
        "  }\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "// Init a sq matrix with rand nums\n",
        "void init_matrix(float* A, int N)\n",
        "{\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "  // Set Matrix dims\n",
        "  int N = 1 << 10; // N dim is 1 shifted over the times = 2^10\n",
        "  size_t bytes = N * N * sizeof(float); // subbing in here float for int so lets keep that in mind\n",
        "\n",
        "  // Allocate memory for matrix\n",
        "\n",
        "  // Creating out pointers\n",
        "  float* d_A;\n",
        "  float* d_B;\n",
        "  float* d_C;\n",
        "\n",
        "  // Allocating memory\n",
        "  cudaMallocManaged(&d_A, bytes);\n",
        "  cudaMallocManaged(&d_B, bytes);\n",
        "  cudaMallocManaged(&d_C, bytes);\n",
        "\n",
        "  // Init our i/p matrices\n",
        "  init_matrix(d_A, N);\n",
        "  init_matrix(d_B, N);\n",
        "\n",
        "  // Set our CTA and Grid sizes\n",
        "  dim3 blockDim(TILE_WIDTH, TILE_WIDTH);\n",
        "  dim3 gridDim((N + TILE_WIDTH - 1) / TILE_WIDTH, (N + TILE_WIDTH - 1) / TILE_WIDTH);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uth9hUFKaHZG"
      },
      "outputs": [],
      "source": [
        "!./tile_matmul1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFPHbZOd9ouu"
      },
      "outputs": [],
      "source": [
        "# Rename the source file\n",
        "!mv t_matmul.cpp t_matmul.cu\n",
        "\n",
        "# Compile for multiple architectures (covers T4, A100, V100)\n",
        "!nvcc -gencode arch=compute_75,code=sm_75 \\\n",
        "      -gencode arch=compute_80,code=sm_80 \\\n",
        "      -gencode arch=compute_70,code=sm_70 \\\n",
        "      t_matmul.cu -o t_matmul\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkwPUmCs98_2"
      },
      "outputs": [],
      "source": [
        "# Run the executable\n",
        "!./t_matmul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69Njs0aN1SaQ"
      },
      "source": [
        "### Atomics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_-xJGRP5sa2"
      },
      "source": [
        "### In a gist --\n",
        "You can think of atomics as a very fast, hardware-level mutex operation. It's as if each atomic operation does this:\n",
        "\n",
        "1. `lock(memory_location)`\n",
        "2. `old_value = *memory_location`\n",
        "3. `*memory_location = old_value + increment`\n",
        "4. `unlock(memory_location)`\n",
        "5. `return old_value`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56qcK3vFr3ML",
        "outputId": "b9102197-43dc-42e9-eec0-ae77868a2539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing atomics.cpp\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%writefile atomics.cpp\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define NUM_THREADS 1000\n",
        "#define NUM_BLOCKS 1000\n",
        "\n",
        "// Kernel without atomics (incorrect)\n",
        "__global__ void incrementCounterNonAtomic(int* counter) {\n",
        "    // not locked\n",
        "    int old = *counter;\n",
        "    int new_value  = old + 1;\n",
        "    // not unlocked\n",
        "    *counter = new_value;\n",
        "}\n",
        "\n",
        "// Kernel with atomics (correct)\n",
        "__global__ void incrementCounterAtomic(int* counter) {\n",
        "  int a = atomicAdd(counter, 1);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int h_counterNonAtomic = 0;\n",
        "    int h_counterAtomic = 0;\n",
        "    int *d_counterNonAtomic, *d_counterAtomic;\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void**)&d_counterNonAtomic, sizeof(int));\n",
        "    cudaMalloc((void**)&d_counterAtomic, sizeof(int));\n",
        "\n",
        "    // Copy initial counter values to device\n",
        "    cudaMemcpy(d_counterNonAtomic, &h_counterNonAtomic, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_counterAtomic, &h_counterAtomic, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernels\n",
        "    incrementCounterNonAtomic<<<NUM_BLOCKS, NUM_THREADS>>>(d_counterNonAtomic);\n",
        "    incrementCounterAtomic<<<NUM_BLOCKS, NUM_THREADS>>>(d_counterAtomic);\n",
        "\n",
        "    // Copy results back to host\n",
        "    cudaMemcpy(&h_counterNonAtomic, d_counterNonAtomic, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(&h_counterAtomic, d_counterAtomic, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print results\n",
        "    printf(\"Non-atomic counter value: %d\\n\", h_counterNonAtomic);\n",
        "    printf(\"Atomic counter value: %d\\n\", h_counterAtomic);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_counterNonAtomic);\n",
        "    cudaFree(d_counterAtomic);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slm7791XDX1P",
        "outputId": "ca93c504-5c92-4cae-8ec0-f064c113e418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing atomics.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile atomics.cpp\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define NUM_THREADS 1000\n",
        "#define NUM_BLOCKS 1000\n",
        "\n",
        "#define CHECK_CUDA(call) {                                   \\\n",
        "    cudaError_t err = call;                                  \\\n",
        "    if (err != cudaSuccess) {                                \\\n",
        "        fprintf(stderr, \"CUDA error in %s (%s:%d): %s\\n\",    \\\n",
        "            #call, __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "        exit(1);                                           \\\n",
        "    }                                                      \\\n",
        "}\n",
        "\n",
        "// Kernel without atomics (incorrect due to race conditions)\n",
        "__global__ void incrementCounterNonAtomic(int* counter) {\n",
        "    int temp = *counter;\n",
        "    temp = temp + 1;\n",
        "    *counter = temp;\n",
        "}\n",
        "\n",
        "// Kernel with atomics (correct)\n",
        "__global__ void incrementCounterAtomic(int* counter) {\n",
        "    atomicAdd(counter, 1);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int h_counterNonAtomic = 0;\n",
        "    int h_counterAtomic = 0;\n",
        "    int *d_counterNonAtomic, *d_counterAtomic;\n",
        "\n",
        "    // Allocate device memory\n",
        "    CHECK_CUDA(cudaMalloc((void**)&d_counterNonAtomic, sizeof(int)));\n",
        "    CHECK_CUDA(cudaMalloc((void**)&d_counterAtomic, sizeof(int)));\n",
        "\n",
        "    // Copy initial counter values to device\n",
        "    CHECK_CUDA(cudaMemcpy(d_counterNonAtomic, &h_counterNonAtomic, sizeof(int), cudaMemcpyHostToDevice));\n",
        "    CHECK_CUDA(cudaMemcpy(d_counterAtomic, &h_counterAtomic, sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Launch kernels\n",
        "    incrementCounterNonAtomic<<<NUM_BLOCKS, NUM_THREADS>>>(d_counterNonAtomic);\n",
        "    CHECK_CUDA(cudaGetLastError());  // Check for launch errors\n",
        "    incrementCounterAtomic<<<NUM_BLOCKS, NUM_THREADS>>>(d_counterAtomic);\n",
        "    CHECK_CUDA(cudaGetLastError());\n",
        "\n",
        "    // Ensure kernels have completed\n",
        "    CHECK_CUDA(cudaDeviceSynchronize());\n",
        "\n",
        "    // Copy results back to host\n",
        "    CHECK_CUDA(cudaMemcpy(&h_counterNonAtomic, d_counterNonAtomic, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "    CHECK_CUDA(cudaMemcpy(&h_counterAtomic, d_counterAtomic, sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Print results\n",
        "    printf(\"Non-atomic counter value: %d\\n\", h_counterNonAtomic);\n",
        "    printf(\"Atomic counter value: %d\\n\", h_counterAtomic);\n",
        "\n",
        "    // Free device memory\n",
        "    CHECK_CUDA(cudaFree(d_counterNonAtomic));\n",
        "    CHECK_CUDA(cudaFree(d_counterAtomic));\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AaVDvJF3wf8"
      },
      "outputs": [],
      "source": [
        "!mv atomics.cpp atomics.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz8jeUEGEkZj"
      },
      "outputs": [],
      "source": [
        "!nvcc -gencode=arch=compute_80,code=sm_80 -O3 -o atomics atomics.cu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owM7idRrHzOz"
      },
      "source": [
        "### Better to use this cmd as its more specific to the GPU im using -- A100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkuamtOZr3GR"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_80 -O3 -o atomics atomics.cu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjlgvVSlr3C5",
        "outputId": "450f96b8-f2ac-466d-c108-eccb36c429b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-atomic counter value: 18\n",
            "Atomic counter value: 1000000\n"
          ]
        }
      ],
      "source": [
        "!./atomics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKboLSKKr2_g",
        "outputId": "5ee9b0f9-4800-444c-c2fc-ed26a2824229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMOY_1cPr270",
        "outputId": "93187370-39cc-485b-cef0-8d79edc0f3a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Feb 18 21:56:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             41W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gImRe2soIZYg"
      },
      "source": [
        "### Cuda Streams ⛰️💧💧"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15e9RT9YR14N"
      },
      "source": [
        "### You can think of streams as \"river streams\" where the direction of operations flows only forward in time (like a timeline).\n",
        "###  For example:\n",
        "* Copy some data over (time step 1),\n",
        "*Then do some computation (time step 2),\n",
        "*Then copy some data back (time step 3).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6YEtK6qST_c"
      },
      "source": [
        "### We can have multiple streams at once in CUDA, and each stream can have its own timeline. This allows us to overlap operations and make better use of the GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYmyCWeaTI3U"
      },
      "source": [
        "###  For example:\n",
        "* When training a massive LLM it would be silly to spend a ton of time loading all the tokens in and out of the GPU.\n",
        "* Streams allow us to move data around while also doing computation at all times. Streams introduce a software abstraction called \"prefetching\", which is a way to move data around before it is needed.\n",
        "*This is a way to hide the latency of moving data around."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9H-aAwPr23n",
        "outputId": "23d498c6-7d2d-4c80-a06f-df8c1e152b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing streams1.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile streams1.cpp\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define CHECK_CUDA_ERROR(val) check((val), #val, __FILE__, __LINE__) // error checking macros to make sure operationns\n",
        "                                                                      // go through succesfully\n",
        "\n",
        "template <typename T>\n",
        "void check(T err, const char* const func, const char* const file, const int line) {\n",
        "    if (err != cudaSuccess) {\n",
        "        fprintf(stderr, \"CUDA error at %s:%d code=%d(%s) \\\"%s\\\" \\n\", file, line, static_cast<unsigned int>(err), cudaGetErrorString(err), func);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < numElements) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    int numElements = 50000;\n",
        "    size_t size = numElements * sizeof(float);\n",
        "    float *h_A, *h_B, *h_C;\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaStream_t stream1, stream2; // use cuda stream type --\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_A = (float *)malloc(size);\n",
        "    h_B = (float *)malloc(size);\n",
        "    h_C = (float *)malloc(size);\n",
        "\n",
        "    // Initialize host arrays\n",
        "    for (int i = 0; i < numElements; ++i) {\n",
        "        h_A[i] = rand() / (float)RAND_MAX;\n",
        "        h_B[i] = rand() / (float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    CHECK_CUDA_ERROR(cudaMalloc((void **)&d_A, size));\n",
        "    CHECK_CUDA_ERROR(cudaMalloc((void **)&d_B, size));\n",
        "    CHECK_CUDA_ERROR(cudaMalloc((void **)&d_C, size));\n",
        "\n",
        "    // Create streams\n",
        "    CHECK_CUDA_ERROR(cudaStreamCreate(&stream1));\n",
        "    CHECK_CUDA_ERROR(cudaStreamCreate(&stream2));\n",
        "\n",
        "    // Copy inputs to device asynchronously\n",
        "    CHECK_CUDA_ERROR(cudaMemcpyAsync(d_A, h_A, size, cudaMemcpyHostToDevice, stream1));\n",
        "    CHECK_CUDA_ERROR(cudaMemcpyAsync(d_B, h_B, size, cudaMemcpyHostToDevice, stream2));\n",
        "\n",
        "    // Launch kernels\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock, 0, stream1>>>(d_A, d_B, d_C, numElements);\n",
        "\n",
        "    // Copy result back to host asynchronously\n",
        "    CHECK_CUDA_ERROR(cudaMemcpyAsync(h_C, d_C, size, cudaMemcpyDeviceToHost, stream1));\n",
        "\n",
        "    // Synchronize streams\n",
        "    CHECK_CUDA_ERROR(cudaStreamSynchronize(stream1));\n",
        "    CHECK_CUDA_ERROR(cudaStreamSynchronize(stream2));\n",
        "\n",
        "    // Verify result\n",
        "    for (int i = 0; i < numElements; ++i) {\n",
        "        if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5) {\n",
        "            fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    printf(\"Test PASSED\\n\");\n",
        "\n",
        "    // Cleaning up resources\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_A));\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_B));\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_C));\n",
        "    CHECK_CUDA_ERROR(cudaStreamDestroy(stream1));\n",
        "    CHECK_CUDA_ERROR(cudaStreamDestroy(stream2));\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLLQShJPr20B"
      },
      "outputs": [],
      "source": [
        "!mv streams1.cpp streams1.cu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAJiJltyr2wV"
      },
      "outputs": [],
      "source": [
        "!nvcc -arch=sm_80 -O3 -o streams1 streams1.cu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEAGbeJMr2tH",
        "outputId": "4a0564e2-5fb1-47a4-b73b-d5addb8dc2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test PASSED\n"
          ]
        }
      ],
      "source": [
        "!./streams1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SESFK4CZr2o8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZptO-loqr2gb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgVNTQuRr2V2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
